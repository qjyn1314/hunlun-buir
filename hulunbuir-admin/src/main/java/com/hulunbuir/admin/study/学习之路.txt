==git学习==
----------------------------------------------------------
git pull时，需要登录的账户和密码						 
账号： 
密码： 
1、是什么？
2、能干什么？
3、去哪下载
4、怎么玩？
5、最后的helloword
git的命令学习:
git status         :查看git提交状态;
git config --list  :查看git设置列表;
git checkout 文件名：撤回已修改的文件;
git pull           ：将远程仓库的的最新代码clone到本地仓库;
git add 文件名     ：将文件添加到本地的栈内存中;
git commit -m "注释"；将文件提交到本地仓库中;
git push           ：将已经提交到本地仓库的文件，推送到远程仓库;
git remote -v      : git查看远程仓库地址;
----------------------------------------------------------
git提交代码：
git status                       ： 查看git提交状态;
git add '文件名'                 ： 将需要提交的文件添加到栈缓存;
git commit -m "提交本次的注释";	 ： 将文件提交到本地仓库中;
git pull                         ： 将远程服务器代码同步到本地;
git push                         ： 推送至远程服务器;
				                 
多个人同时修改一个类时，更新时会发生冲突			 
解决方法：					                                 
1、git stash ：将本地中所有的的需要更新的放入git栈中;	 
2、git pull ：更新至最新的代码;						         
3、git stash pop ：将git栈中的文件进行弹栈;				 
4、git status : 查看文件中发生冲突的文件，将其中的冲突解决后，进行提交;	 
5、git status ：查看当前的哪些文件是需要提交到远程库中的;	 
6、git add ：将发生冲突的文件添加到本地库中;					 
7、git reset ：将不需要修改的文件从本地仓库中撤回;			 
8、git commit -m "提交本次的注释" ;					     
9、git push ：将本地仓库中更新的代码，推送至远程仓库。	     
------------------------------------------------------------|
永久记住git客户端提交代码时输入的账号和密码					 
在命令行输入命令:					                         
前提是已经输入过账号和密码；				            	 
git config --global credential.helper store					 
这一步会在用户目录下的.gitconfig文件最后添加：      		 
[credential] helper = store					                 
通过命令git config --list					            	 
来检查，是否有credential.helper=store这个属性				 
再次打开git客户端，来检查效果；					            
------------------------------------------------------------|
创建分支：

1、在创建分支的时候需要基于某个分支的代码进行创建，切换到基础分支，如主干
git checkout master
2、创建并切换到新分支
git checkout -b test
4、推送到远程
git push origin test
5、设置新创建的分支的上游分支
git branch --set-upstream-to=origin/test test
git branch --set-upstream-to=origin/zookeeper zookeeper 
6、查看所有分支
git branch -a  可以看到已经在test分支上
git push origin test
------------------------------------------------------------|
合并步骤：
1、进入要合并的分支（如开发分支合并到master，则进入master目录）
git checkout master
git pull

2、查看所有分支是否都pull下来了
git branch -a

3、使用merge合并开发分支
git merge 分支名

4、查看合并之后的状态
git status

5、有冲突的话，通过IDE解决冲突；

6、解决冲突之后，将冲突文件提交暂存区
git add 冲突文件

7、提交merge之后的结果
git commit

如果不是使用git commit -m "备注" ，那么git会自动将合并的结果作为备注，提交本地仓库；

8、本地仓库代码提交远程仓库
git push

git将分支合并到分支，将master合并到分支的操作步骤是一样的
-----------------------------------------------------------------------------------------------------------------------------------------
合并某个分支上的单个commit
首先，用git log或sourcetree工具查看一下你想选择哪些commits进行合并，例如：

比如feature 分支上的commit 82ecb31 非常重要，它含有一个bug的修改，或其他人想访问的内容。无论什么原因，你现在只需要将82ecb31 合并到master，而不合并feature上的其他commits，所以我们用git cherry-pick命令来做：

git checkout master  

git cherry-pick 82ecb31

这样就好啦。现在82ecb31就被合并到master分支，并在master中添加了commit（作为一个新的commit）。cherry-pick 和merge比较类似，如果git不能合并代码改动（比如遇到合并冲突），git需要你自己来解决冲突并手动添加commit。

这里
git cherry-pick
每次合并过来会显示文件冲突(其实并没有冲突代码部分，只需手动解决既可)
------------------------------------------------
git进行回退到某一版本
1、查看日志：git log
2、然后将回退到某一版本的提交ID进行记录，
   命令：git reset --hard 某一版本的提交记录ID 
3、最后进行强制推送到远程仓库
	查看当前的分支名称，命令：git branch -a
   命令：git push -f origin 当前分支名称
4、进行查看是否回退成功
   命令：git log 
----------------------------------------------------------------------------------------------
更改git项目的远程地址命令：
git remote set-url origin  新的远程地址
git remote set-url origin https://giterp.xibei.com.cn/icibei/iciyun-adi-microframe-costcard.git
------------------------------------------------------------------------------------------------------
将本地项目推送至github中

1.创建好远程仓库，并设置为public中--https://github.com/qjyn1314/day-cloud.git

2.在本地文件夹中执行命令：
git init
git add .
git commit -m "备注"

3.git remote add origin https://github.com/qjyn1314/day-cloud.git
git remote add origin https://github.com/qjyn1314/calm-cloud.git

4.git pull
这个时候可能会出现：fatal: refusing to merge unrelated histories
(致命的:拒绝合并不相关的历史)

解决：git pull origin master --allow-unrelated-histories

git pull origin main --allow-unrelated-histories

5.git push 进行推送至远程
-----------------------------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------------------
seata-server.sh -h 127.0.0.1 -p 8091 -m db
seata-server.bat -h 127.0.0.1 -p 8091 -m db

startup.cmd -m standalone

------------------------------------------------------------------------------------------------------------------------------------
学习参考：
spring的事件监听：
https://blog.csdn.net/likun557/article/details/106045522


-----------------------------------------------------------------------------------------------------------------------------------------------------
360
谷歌浏览器
谷歌上网助手插件
搜狗输入法
QQ
微信
Notepad++
jdk
maven
node
git
idea
navcat
tomcat
-----------------------------------------------------------------------------------------------------------------------------------------------------
效验数据
处理数据
调用接口
返回数据
-----------------------------------------------------------------------------------------------------------------------------------------------------
mybatis的常用开发代码：
 
 <include refid="query_where"/>
 
 <sql id="query_where">
    
 </sql>
<if test="title != null and title != ''">
	and  title like  CONCAT('%', #{title,jdbcType=VARCHAR}, '%')
</if>
<if test="cultureZxType != null and cultureZxType != ''">
      and  culture_zx_type = #{cultureZxType,jdbcType=VARCHAR}
    </if>
<if test="pubDateStart != null and pubDateEnd != null ">
	and  pub_date BETWEEN #{pubDateStart} AND #{pubDateEnd} 
</if>

  BETWEEN用法-->参考：https://www.cnblogs.com/tianzeng/p/9279593.html
	// int 时间戳格式，查询 2008-08-08 20:00:00 到 2009-01-01 零点之前的数据
	SELECT * FROM table WHERE column_time BETWEEN 1218196800 AND 1230739199

	// DATE 格式，查询 2008-08-08 到 2009-01-01 零点之前的数据
	SELECT * FROM table WHERE column_time BETWEEN '2008-08-08' AND '2009-01-01'
	 
	// DATETIME 格式，查询 2008-08-08 20:00:00 到 2009-01-01 零点之前的数据
	SELECT * FROM table WHERE column_time BETWEEN '2008-08-08 20:00:00' AND '2008-12-31 23:59:59'
	
	但对于查询到当前时间的数据，建议使用 >= 运算符：
	// DATETIME 格式，查询 2008-08-08 20:00:00 到当前时刻的数据
	SELECT * FROM table WHERE column_time >= '2008-08-08 20:00:00'
				
<![CDATA[ and  pub_date >= #{pubDateStart} and pub_date <= #{pubDateEnd} ]]>
<if test="pubDateStart != null and pubDateEnd != null ">
 and  pub_date &gt;= #{pubDateStart} and pub_date &lt;= #{pubDateEnd} 
</if>
mybatis中的小于号参考：
https://blog.csdn.net/xuanzhangran/article/details/60329357

第一种写法（1）：

原符号       <        <=      >       >=       &        '        "
替换符号    &lt;    &lt;=   &gt;    &gt;=   &amp;   &apos;  &quot;
例如：sql如下：
create_date_time &gt;= #{startTime} and  create_date_time &lt;= #{endTime}

第二种写法（2）：
大于等于
<![CDATA[ >= ]]>
小于等于
<![CDATA[ <= ]]>
例如：sql如下：
create_date_time <![CDATA[ >= ]]> #{startTime} and  create_date_time <![CDATA[ <= ]]> #{endTime}

<if test="pubDateStart != null and pubDateEnd != null">
	and pub_date &gt;= DATE_FORMAT(#{pubDateStart},'%Y-%m-%d %H:%i:%s') and pub_date &lt;= DATE_SUB( DATE_ADD(#{pubDateEnd}, INTERVAL 1 DAY),INTERVAL 1 SECOND)
</if>
参考与：https://blog.csdn.net/as875784622/article/details/100918185

------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------

SPRINGSECURITY

OAUTH2
 
------------------------------------------------------------------------------------------------------------------------------------------------
搭建 springcloud + mybatis + nocas + gatway 


创建springcloud项目

Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里

Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台

Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求

Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题

Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务
 
 
------------------------------------------------------------------------------------------------
 
nginx配置代理服务

	server {
        listen       80;
        server_name  admin.hulunbuir.vip;
        #access_log   /usr/local/nginx/logs/hulunbuir.access.log main;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            #root   html;
            #index  index.html index.htm;
            proxy_pass  http://47.104.78.115:8026;
			proxy_pass  http://47.104.78.115:8016;
            #proxy_redirect default;
        }
	}

美剧：
权利的游戏
西部世界 
良医
爱乐之城
天赋异禀

https://halo.run/archives/install-with-linux

sudo curl -o /etc/systemd/system/halo.service --create-dirs https://dl.halo.run/config/halo.service

# 使 Halo 开机自启
sudo systemctl enable halo

# 启动 Halo
sudo service halo start

# 重启 Halo
sudo service halo restart

# 停止 Halo
sudo service halo stop

# 查看 Halo 的运行状态
sudo service halo status
 
---------------------------------
一个单向链表，有N个节点。删除倒数第3个节点，要求有较优的时间复杂度和空间复杂度
---------------------------------
 
---------------------------------
idea的常用插件：

Free Mybatis plugin

Alibaba Java Coding Guidelines  

CamelCase -- shift+alt+U 

Maven helper

mybatisx

translation

Lombok

Git Commit Template

javaDoc :

要为活动元素生成 javadocs，请按 shift + alt + G。
要为当前 java 文件中的所有元素生成 javadocs，请按 shift + ctrl + alt + G。
删除当前/选定元素上的 javadocs 请按 shift + alt + Z。
删除当前类所有元素上的 javadocs：请按 shift + ctrl + alt + Z。

FindBugs

SQL Query Plugin

Mybatis-log-plugin

Grep Console

BackgroundImagePlus

Jrebel

CheckStyle

BashSupport

idea features trainer

MetricsReloaded  代码复杂度检查

Statistic 代码统计

GsonFormat  把 JSON 字符串直接实例化成类

Jindent-Source C
ode Formatter   自定义类、方法、doc、变量注释模

ECTranslation

SequenceDiagram

Leetcode Editor

Codota

Zoolytic

SequenceDiagram for IntelliJ IDEA   

IdeaJad
idea中的常用注释

注释：
类，接口，枚举，抽象类
/**
 * <p>
 * explain:
 * </p>
 *
 * @author wangjunming
 * @since ${DATE} ${TIME}
 */

方法：
/**
 * 
 * 
 * @author wangjunming
 * @since $date$ $time$
 */
 
常用工具
文本比较工具：
beyond compare

性能测试工具：
Jmeter

-----------
基金理财学习：
购选基金的基本要点，
1.单位净值
2.历史净值
3.市盈率
4.日增长率
5.波动率
-----------

url: jdbc:mysql://192.168.20.229:3306/qdcy-standards?autoReconnect=true&useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull&useSSL=false&serverTimezone=Asia/Shanghai
username: dbuser
password: dbus24^*

---------------------------------

mvn clean package -U  -Dmaven.test.skip=true

mvn clean deploy -e 

------------------
 
https://blog.csdn.net/qq_38011415/article/details/85227681
 
https://blog.csdn.net/u011961421/article/details/79779650?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.nonecase
 
https://blog.csdn.net/xcc_2269861428/article/details/99996185?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase
 
https://blog.csdn.net/upxiaofeng/article/details/79415108

------------------

frog
地址：http://101.200.32.71:8082/ui/login/
账号：admin
密码：admin!@#123

-------------------------------------
 
yanglianyun  60.205.212.217	 
rongxinlian  47.108.65.18
tianchang  47.97.43.205
ciyun  101.201.48.96 

旅游计划1：
哈尔滨-->东升雪谷-->雪乡-->二浪河-->亚布力

中央大街(马迭尔冰棍)-->圣索菲亚大教堂-->松花江-->

亚布力(雪韵大街、林海古镇、亚布力滑雪场)-->中国雪乡(雪乡国家森林公园、)
------------------------------------------------------------------------------------------------ 
mysql学习收藏之一：
https://www.bilibili.com/video/BV12b411K7Zu?p=76
mysql更换字符集：
##查看当前数据库字符集
SHOW VARIABLES like '%char%';
#更改相应的字符集
set character_set_client = 'utf8';

#设置时间为中国时间
show VARIABLES LIKE '%time_zone%';
set GLOBAL time_zone = '+08:00';

##字段中的别名在五个字句中都可以使用
SELECT t.id ID,t.team_name teamName,t.dataes dateEs,COUNT(*) sumCount FROM team t WHERE ID > 0  GROUP BY teamName  HAVING ID < 3 AND sumCount > 0 ORDER BY ID ASC ;
##查看SQL的执行计划
EXPLAIN SELECT t1.team_name '主队',t2.team_name '客队',s.score '比分',s.`data` '比赛日期' FROM score s LEFT JOIN team t1 ON s.team_one = t1.id LEFT JOIN team t2 ON s.team_two = t2.id;
#查看mysql执行计划
EXPLAIN extended SELECT * FROM team WHERE team_name like '%香%';

##查看当前数据库字符集
SHOW VARIABLES like '%char%';
#更改相应的字符集--GLOBAL 表示全局
SET character_set_client = 'utf8';

SELECT * FROM team;

#查看表索引
SHOW INDEX FROM team;\G
show keys from `表名`;
#创建索引单值索引
CREATE INDEX id_index ON team(team_name(5));
#创建复合索引
#在创建复合索引时，每一列都定义了升序或者是降序。如定义一个复合索引
CREATE INDEX idx_example ON table1 (col1 ASC, col2 DESC, col3 ASC);
#删除索引
DROP INDEX id_index ON team;

-- SQL 性能下降的原因(执行时间长、等待时间长)：
-- 1、查询语句写的烂
-- 2、索引失效(单值索引、复核索引)
-- 3、查询的join太多(设计缺陷或者不得已的需求)
-- 4、服务器调优及各个参数设置(缓冲、线程数等)

-- SQL执行加载顺序
-- 1、手写的顺序：
-- SELECT DISTINCT FROM JOIN ON WHERE GROUP BY HAVING ORDER BY LIMIT
-- 2、机读的顺序：
-- FROM      ON        JOIN              WHERE                GROUP BY        HAVING          SELECT    DISTINCT    ORDER BY          LIMIT 
-- 笛卡尔积  主表保留  不符合ON的也添加  非聚合/非select别名  改变对表的引用  只作用于分组后  查询数据  将结果去重  可使用SELECT别名  分页(rows,offset)

-- 索引的优缺点：
-- 优点：
-- 1、通过创建唯一索引，可以保证数据库中表中每一行数据的唯一性
-- 2、大大加快数据检索的数据，这是创建索引的主要原因
-- 3、可以加快表与表的链接，特别是在实现数据的参照完整性方面特别有意义
-- 4、在使用分组和排序字句进行检索时，同样可以显著减少查询中的分组和排序的时间
-- 5、通过使用索引，可以在查询过程中，使用优化隐藏器，提高系统的性能
-- 缺点：
-- 1、创建索引和维护索引要耗时间，这种时间随着数量的增加而增加
-- 2、索引需要占物理空间，除啦数据表占据数据空间外，每一个索引还要占据一定的物理空间，如果建立聚簇索引，那么需要的空间会更大
-- 3、当对数据进行添加和修改、删除时，索引也要动态维护，这样就降低了数据的维护速度
-- 
-- 索引的分类-->参考：https://blog.csdn.net/liutong123987/article/details/79384395
-- 1. FULLTEXT
-- 即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。
-- 全文索引并不是和MyISAM一起诞生的，它的出现是为了解决WHERE name LIKE “%word%"这类针对文本的模糊查询效率较低的问题。
-- 2. HASH
-- 由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。 HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。 
-- 3. BTREE
BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。
-- 4. RTREE
-- RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。
-- 索引种类:
-- 普通索引：仅加速查询
-- 唯一索引：加速查询 + 列值唯一(可以有null)
-- 主键索引：加速查询 + 列值唯一(不可以有null) + 表中只有一个
-- 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并
-- 全文索引：对文本的内容进行分词，进行搜索
-- ps.
-- 索引合并，使用多个单列索引组合搜索
-- 覆盖索引，select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖

-- 索引检索的原理：
-- 参考：https://www.cnblogs.com/aspwebchh/p/6652855.html 
-- https://blog.csdn.net/tongdanping/article/details/79878302 

-- 适合建立索引的场景：
-- 1、
-- 在经常需要搜索的列上，可以加快搜索的速度。
-- 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构。
-- 在经常用在连接的列上，这 些列主要是一些外键，可以加快连接的速度。
--  在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的。
-- 在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。
-- 在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。
 
-- 不适合建立索引的场景：
-- 1、
-- 对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。
-- 对于那些只有很少数据值（唯一性差）的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。
-- 对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。
-- 当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。
------------------------------------------
-- EXPLAIN 语句查询出来的信息解析详解，各个列所表达的意思
-- EXPLAIN 执行过后所展示的列名称："id" "select_type" "table" "partitions" "type"	"possible_keys"	"key" "key_len"	"ref"	"rows" "filtered" "Extra"
-- 参考：https://www.cnblogs.com/butterfly100/archive/2018/01/15/8287569.html

-- id列：编号是select的序列号，有几个select就有几个ID，并且ID的顺序是按select出现的顺序增长的。
-- MySQL将select查询分为简单查询和复杂查询，复杂查询分为三类：简单子查询，派生表(from语句中的子查询),
-- union查询的结果总是放到一张临时表中，临时表不在SQL中出现，所以使用union查询的语句，ID为null

-- select_type列：表示对应的行是简单查询还是复杂查询，出现的值：
-- simple：简单查询查询不包含子查询和union
-- primary：复杂查询中最外层的select
-- subquery：包含在select中的子查询（不在from字句中）
-- derived：包含在from字句中的子查询。MySQL会将结果存放在一个临时表中，也成派生表(derived的英文含义)
-- union：在union中的第二个和随后的select

-- table列：表示正在访问的是哪个表

-- type列：表示关联类型或访问类型，即MySQL决定如何查找表中的行 
-- 依次从最优到最差分别：system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL
-- NULL:mysql能够在优化阶段分解查询语句，在执行阶段用不着在访问表或索引。
-- system ，const:MySQL能对插叙的某部分进行优化并将其转化成一个常量，用于主键或唯一索引的所有列与常数比较式，所以表最多有一个匹配行，读取一次，速度较快。
-- eq_ref：表中的主键或唯一索引的所有部分被连接使用，最多只会返回一条符合条件的记录，这可能是const之外最好的链接类型了。
-- ref：相比eq_ref，不使用唯一索引，而是普通索引或者唯一性索引部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。
-- ref_or_null：与ref类似，但是可搜索值为null的行。
-- index_merge：标识使用了索引合并的优化方法。例如ID是主键，tenant_id是普通索引，or的时候没有使用主键，而是使用了主键和tenant_id索引。
--              explain select * from role where id = 11011 or tenant_id = 8888;
-- range：范围扫描通常出现在in(),between,>,<,>=等操作中，使用索引来检索给定范围的行。
-- index：与ALL一样，不同的就是MySQL只需要扫描数，这通常比ALL块一些。
-- ALL：即全表扫描，意味着MySQL需要从头到尾去查找所需要的行，通常下这需要增加索引来进行优化。

-- possible_keys列：这一列显示查询可能使用那些索引来查找。

-- key列：显示MySQL实际采用哪个索引来优化对该表的访问。

-- key_len列：显示MySQL在索引里使用的字节数，通过这个值可以算出具体使用了索引中的那些列。
-- 索引最大长度是768字节，当字符串过长时，MySQL会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。

-- ref列：显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：const（常量），func，NULL。

-- rows列：是MySQL估计要读取并检测的行数，注意这个不是结果集里的行数。

-- extra列：展示的是额外信息。

-- -- -- -- -- -- -- -- -- -- -- 
索引优化：
 
索引： 索引(Index)是帮助MySQL高效获取数据的数据结构。由此可得到索引的本质是一种数据结构。
简单理解为： 排好序的快速查找数据结构。

索引就是数据库创建的满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据
索引的结构和索引的检索原理

相关概念
B-树（B树）：多路搜索树，每个结点存储M/2到M个关键字，非叶子结点存储指向关键字范围的子结点；所有关键字在整颗树中出现，且只出现一次，非叶子结点可以命中；
B+树：在B-树基础上，为叶子结点增加链表指针，所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中；

结构：默认是B+Tree树

为什么使用？
单节点能存储更多的数据，使得测判IO次数更少
叶子节点形成有序链表，便于执行范围操作
聚集索引中，叶子结点的data直接包含数据；
非聚集索引中，叶子结点中存储数据地址的指针

索引的分类：
唯一索引：
主键索引
唯一索引

联合索引：
联合主键索引
联合唯一索引
联合普通索引
 
================================================================================================================================================
================================================================================================================================================
 
数据库提供了四种事务隔离级别, 不同的隔离级别采用不同的锁类开来实现. 

在四种隔离级别中, Serializable的级别最高, Read Uncommited级别最低. 

大多数数据库的默认隔离级别为: Read Commited,如Sql Server , Oracle. 

少数数据库默认的隔离级别为Repeatable Read, 如MySQL InnoDB存储引擎 

即使是最低的级别,也不会出现 第一类 丢失 更新问题 .  

1. 脏读(事务没提交，提前读取)：

脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 

2. 不可重复读(两次读的不一致):

是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。例如，一个编辑人员两次读取同一文档，但在两次读取之间，作者重写了该文档。当编辑人员第二次读取文档时，文档已更改。原始读取不可重复。如果只有在作者全部完成编写后编辑人员才可以读取文档，则可以避免该问题。
 
3. 幻读(更新或插入之后，又发现新存在的数据):

是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。例如，一个编辑人员更改作者提交的文档，但当生产部门将其更改内容合并到该文档的主复本时，发现作者已将未编辑的新材料添加到该文档中。如果在编辑人员和生产部门完成对原始文档的处理之前，任何人都不能将新材料添加到文档中，则可以避免该问题。 

4.第一类更新丢失(回滚丢失):
当2个事务更新相同的数据源，如果第一个事务被提交，而另外一个事务却被撤销，那么会连同第一个事务所做的跟新也被撤销。也就是说第一个事务做的跟新丢失了。 
5.第二类更新丢失(覆盖丢失):
第二类更新丢失实在实际应用中经常遇到的并发问题，他和不可重复读本质上是同一类并发问题，通常他被看做不可重复读的特例：当2个或这个多个事务查询同样的记录然后各自基于最初的查询结果更新该行时，会造成第二类丢失更新。因为每个事务都不知道不知道其他事务的存在，最后一个事务对记录做的修改将覆盖其他事务对该记录做的已提交的更新... 

#事务的特性：
-- ACID：原子性，一致性，隔离性，持久性
#事务并发问题是如何发生的？
-- 多个事务 同时  操作 同一个数据库的相同数据时
-- 一个事务与其他事务隔离的成都称为隔离级别,其中隔离级别越高，数据一致性就越好，但并发行越弱：
-- 脏读（读未提交（read-uncommitted））：
-- 一个事物读取了其他事物“更新”还没有提交的数据
-- 对于两个事务T1,T2,T1读取了已经被T2更新但还没有被提交的字段之后，若T2回滚，T1读取的内容就是临时且无效的。
-- 
-- 不可重复读（读已提交（read-committed））：
-- 一个事物多次读取数据，结果不一样
-- 对于两个事务T1,T2,T1读取了一个字段，然后T2更新了该自担之后，T1再次读取同一个字段，值就不同了。
-- 
-- 幻读（可重复读（repeatable-read））：
-- 一个事物读取了其他事务还没有提交的数据，只是读到的是其他事务插入的数据
-- 对于两个事务T1，T2，T1从一个表中读取了一个字段，然后T2在该表中插入了一些新的记录后，T1再次读取同一表，就会多出几条记录。

#如何解决并发的事务问题：
-- 通过这事隔离级别来解决并发的问题
 
一、事务的基本要素（ACID）

1、原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。

2、一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。

3、隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账

4、持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。

二、事务的并发问题

　　1、脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据

　　2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。

　　3、幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。

　　小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表

三、MySQL事务隔离级别-从低到高：

		事务隔离级别	            	脏读	不可重复读	幻读
		读未提交（read-uncommitted）	是		是			是
		读已提交（read-committed）		否		是			是
msyql->>可重复读（repeatable-read） 	否		否			是
		串行化（serializable）			否		否			否

====:: mysql默认的事务隔离级别为 ：repeatable-read  可重复读

mysql事务的实现原理：主要是通过日志表来实现

** https://cloud.tencent.com/developer/article/1431307 

https://www.lagou.com/lgeduarticle/82740.html

================================================================================================================================================
================================================================================================================================================

补充 : 基于元数据的 Spring 声明性事务 : 

Isolation 属性一共支持五种事务设置，具体介绍如下： 

DEFAULT 使用数据库设置的隔离级别 ( 默认 ) ，由 DBA 默认的设置来决定隔离级别

READ_UNCOMMITTED (读未提交) 会出现脏读、不可重复读、幻读 ( 隔离级别最低，并发性能高 ) 

READ_COMMITTED (读已提交)  会出现不可重复读、幻读问题（锁定正在读取的行） 

REPEATABLE_READ () 会出幻读（锁定所读取的所有行） 

SERIALIZABLE 保证所有的情况不会发生（锁表） 

不可重复读的重点是修改 : 
同样的条件 ,   你读取过的数据 ,   再次读取出来发现值不一样了 
幻读的重点在于新增或者删除 
同样的条件 ,   第 1 次和第 2 次读出来的记录数不一样
----------------------------------------------------------
事务传播行为种类
Spring在 TransactionDefinition 接口中规定了7种类型的事务传播行为，
它们规定了事务方法和事务方法发生嵌套调用时事务如何进行传播：
事务传播行为类型
PROPAGATION_REQUIRED
 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。

PROPAGATION_SUPPORTS
 支持当前事务，如果当前没有事务，就以非事务方式执行。
 
PROPAGATION_MANDATORY
 使用当前的事务，如果当前没有事务，就抛出异常。
 
PROPAGATION_REQUIRES_NEW
 新建事务，如果当前存在事务，把当前事务挂起。
 
PROPAGATION_NOT_SUPPORTED
 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
 
PROPAGATION_NEVER
 以非事务方式执行，如果当前存在事务，则抛出异常。
 
PROPAGATION_NESTED
 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。
 
================================================================================================================================================
================================================================================================================================================
在多线程的应用场景下：
 
 1、同步锁 
 同步块的锁是：
 --任意的，创建出来的对象实例
 同步函数的锁是：
 --是当前的对象，也就是this
 静态同步函数锁是：
 --因为是静态的，随着类的加载而加载，所以锁是：当前类名.class
 
 2、创建线程的方法： 
 创建线程：继承thread类，复写父类的run方法，start开启线程；
 
 复写run方法的作用
 run方法是用于存储线程所需要执行的自定义代码。
 
 创建继承Thread类的线程，并执行start方法
 start是来开启线程，调用run方法中需要执行的自定义代码，
 
 3、线程的状态
 直接运行run方法就是直接来运行自定义的代码，并没有开启一个线程去执行自定义代码，
    而是跟主线程一样，当前就只有一个主线程在执行
 线程的几种状态：
 被创建（start()）；
 运行（run()）；
 临时状态（sleep(time)）具备执行资格，但是没有执行权，时间一到则开始执行；
 冻结状态（wait()）放弃了执行资格，也可以传参数，时间一到则也开始执行；
 唤醒线程（notify()）,唤醒冻结状态的的线程；
 消亡（stop()，run方法结束）；
 
 4、 死锁：
 互斥条件：一个资源每次只能被一个进程使用。
 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺。
 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。
 
线程同步： synchronized 和 Lock 的对比 
 
 Lock是显示锁（手动的开启和关闭锁）
 synchronized是隐式锁（出了作用域就自动释放锁）
 使用lock锁，jvm将花费较少的时间来调度线程，性能更好
 优先使用顺序：lock>同步代码块（已经进入了方法体，分配了相应资源）>同步方法（在方法体之外）

---------------------------------------------------------------------------

抽象类的特点，
有抽象方法的类必须是抽象类
抽象类不能创建(new)对象，
抽象类中的方法是

------------------------------------------------------------------------------------------------
微信进行绑定：
触发aouth2的静默授权，然后获取到code，将code放到回调的url上，
前端将这个code再次请求后台接口，
-->接口中会访问微信的服务器，
换取AccessToken,openid,
再次访问微信的服务器，将用户的基本信息，返回给前端，
前端拿到这个信息之后，用户绑定的时候，将这个用户的基本信息后存储到数据库中；
-----------------------------------------------------------------------------------------------------------
项目经验总结：
1、明确你的项目到底是做什么的，有哪些功能
2、明确你的项目的整体架构，在面试的时候能够清楚地画给面试官看并且清楚地指出从哪里调用到哪里、使用什么方式调用
3、明确你的模块在整个项目中所处的位置及作用
4、明确你的模块用到了哪些技术，更好一些的可以再了解一下整个项目用到了哪些技术
------------------------------------------------------------------------------------------------------------ 
项目中解决的复杂的问题：

在使用rabbitmq进行丢入消息的时候，监听器进行解析数据，出现了乱码的情况
解决的思路：首先出现的乱码，将转换成为UTF-8的字符集，然后是否是序列化的问题，实现序列化的时候需要加上序列化ID。

最后发现在解析的时候出现了问题，之前使用的是架构师自己封装的json处理工具，改过之后使用了alibaba的json处理，进行转换成对象数据

在mysql中使用的group by 的问题，在查询的字段的时候由于没有对其他字段进行聚合函数求值，这个时候sql会报错有group by的问题，
没有对所需要查询的字段进行聚合函数运算的时候，会有sql语句的group by 的问题，
最后解决就是使用的是any_value()函数解决，将需要查询的字段使用此函数
-------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
nginx的学习之路：
参考：https://blog.csdn.net/w410589502/article/details/70787468
linux上安装nginx
1、下载最新的nginx：
wget http://nginx.org/download/nginx-1.17.7.tar.gz  
tar -zxvf nginx-1.17.7.tar.gz 
mv nginx-1.17.7 nginx-1.17
进入目录 cd nginx-1.17 

2、安装依赖：
yum install gcc-c++ -y
yum install -y pcre pcre-devel
yum install -y zlib zlib-devel
yum install -y openssl openssl-devel
安装成功之后则执行：
./configure
3、编译安装：
make install
查看安装之后的路径：
whereis nginx
4、启动、停止nginx
启动和停止nginx的命令
（1）先进入nginx的目录
cd /usr/local/nginx/sbin/
（2）再执行命令
1 ./nginx 开启
2 ./nginx -s stop 停止
3 ./nginx -s quit 退出
4 ./nginx -s reload 重启 
./nginx -s quit:此方式停止步骤是待nginx进程处理任务完毕进行停止。
./nginx -s stop:此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程。

------------------------------------------------------------------------------------------------------------------------
LINUX学习之路：
cat /etc/redhat-release    ：查看Linux的系统版本；
=======================================================================================================================
CENTOS7.5安装MYSQL:
cat /etc/redhat-release    ：查看Linux的系统版本；
1、进入：/usr/local/mysql  执行命令：wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm
2、rpm -ivh mysql-community-release-el7-5.noarch.rpm
3、yum install mysql-community-server
4、service mysqld restart ：重启MySQL服务；
5、mysql -u root     
6、set password for 'root'@'localhost' =password('1234567');
注意：以上命令执行就是在/usr/local/mysql目录下执行，若是没有该目录，则创建
7、远程连接设置
把在所有数据库的所有表的所有权限赋值给位于所有IP地址的root用户。
执行命令：mysql> grant all privileges on *.* to root@'%' identified by '1234567';
如果是新用户而不是root，则要先新建用户
执行命令：mysql>create user 'username'@'%' identified by 'password';  
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '1234567'; 
将设置生效
FLUSH PRIVILEGES;
============================================================================================================================================
https://www.darknetmarkets.com/ultimate-dark-web-toolbox/   
====================================================================================================================================
============================================================================================================================================
static{}：
这叫静初始化代码块。静态初始化代码块在类加载的时候执行，这是在任何对象创建之前，且只执行一次。
{}：
这个是：代码块。在每一次创建对象之前执行，
============================================================================================================================================
============================================================================================================================================

查看linux中所占用的端口号
sudo netstat -tunlp
此命令中使用的选项具有以下含义：
-t - 显示 TCP 端口。
-u - 显示 UDP 端口。
-n - 显示数字地址而不是主机名。
-l - 仅显示侦听端口。
-p - 显示进程的 PID 和名称。仅当您以 root 或 sudo 用户身份运行命令时，才会显示此信息。
--------------------------
 
1.netstat  -anp  |grep   端口号

如下，我以3306为例，netstat  -anp  |grep  3306（此处备注下，我是以普通用户操作，故加上了sudo，如果是以root用户操作，不用加sudo即可查看） 

 主要看监控状态为LISTEN表示已经被占用，最后一列显示被服务mysqld占用，查看具体端口号，只要有如图这一行就表示被占用了。

2.netstat -nultp   （此处不用加端口号）

该命令是查看当前所有已经使用的端口情况 
 
3.netstat  -anp  |grep  82查看82端口的使用情况 
 
-----------------------------------------------------------------------------------
 
nohup java -Xms512m -Xmx512m -jar /usr/local/deploy/hulunbuir-afternoon.jar >/dev/null 2>&1 &

nohup java -Xms512m -Xmx512m -jar /usr/local/deploy/hulunbuir-admin.jar >/dev/null 2>&1 &

nohup java -Xms512m -Xmx512m -jar /usr/local/deploy/hulunbuir-evening.jar >/dev/null 2>&1 &

ps -ef | grep hulunbuir-afternoon | grep -v grep | cut -c 9-15 | xargs kill -s 9

--------------------------------------------------------------------------------------------------------------------------------------------

生成代码项目源码地址：https://github.com/qjyn1314/hunlun-buir.git/
生成代码的工具在hulunbuir-afternoon项目中
访问网址：http://www.hulunbuir.vip/
账号：qjyn1314@163.com
密码：123456
数据库：47.104.78.115:3308
账号：root
密码：1234567

--------------------------------------------------------------------------------------------------------------------------------------------

export LANG=zh_CN.UTF-8
cd /home/hulunbuir/
git pull 
mvn clean install -U
echo "复制启动jar包"
cp -f /home/hunlun-buir/hulunbuir-afternoon/target/hulunbuir-afternoon.jar /usr/local/deploy  
cp -f /home/hunlun-buir/hulunbuir-admin/target/hulunbuir-admin.jar /usr/local/deploy  
cp -f /home/hunlun-buir/hulunbuir-evening/target/hulunbuir-evening.jar /usr/local/deploy  

echo "进入目标文件夹"
cd /usr/local/deploy
echo "查看所进入的路径"
pwd 
echo "查看是否有文件"
ls -a
#杀掉进程
ps -ef | grep hulunbuir

ps -ef | grep hulunbuir-afternoon | grep -v grep | cut -c 9-15 | xargs kill -s 9

ps -ef | grep hulunbuir

echo "开始启动项目"
 
nohup java -Xms512m -Xmx512m -jar /usr/local/deploy/hulunbuir-afternoon.jar >/dev/null 2>&1 &

exit
eeooff
echo 'done!'

---------------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------------------------
linux中创建文件和文件夹
Linux文件夹或文件创建、删除
Linux删除文件夹命令
linux删除目录很简单，很多人还是习惯用rmdir，不过一旦目录非空，就陷入深深的苦恼之中，现在使用rm -rf命令即可。
直接rm就可以了，不过要加两个参数-rf 即：rm -rf 目录名字

删除目录、文件 rm(remove)

功能说明：删除文件或目录。
语　　法：rm [-dfirv][--help][--version][文件或目录...]
补充说明：执行rm指令可删除文件或目录，如欲删除目录必须加上参数”-r”，否则预设仅会删除文件。
参　　数：
　-d或–directory 　直接把欲删除的目录的硬连接数据删成0，删除该目录。
　-f或–force 　强制删除文件或目录。
　-i或–interactive 　删除既有文件或目录之前先询问用户。
　-r或-R或–recursive 　递归处理，将指定目录下的所有文件及子目录一并处理。
　-v或–verbose 　显示指令执行过程。

1 删除文件夹
de>rm -rf fileNamede>

-删除文件夹实例：
rm -rf /var/log/httpd/access
将会删除/var/log/httpd/access目录以及其下所有文件、文件夹
需要提醒的是：使用这个rm -rf的时候一定要格外小心，linux没有回收站的

2 删除文件
de>rm -f fileNamede>

Linux添加文件命令

创建目录：mkdir(make directories)

功能说明：建立目录
语　　法：mkdir [-p][--help][--version][-m <目录属性>][目录名称]
补充说明：mkdir可建立目录并同时设置目录的权限。
参　　数：
-m<目录属性>或–mode<目录属性> 建立目录时同时设置目录的权限。
-p或–parents 若所要建立目录的上层目录目前尚未建立，则会一并建立上层目录。

例：mkdir test

创建文件 touch

功能说明：改变文件或目录时间。
语　　法：touch [-acfm][-d <日期时间>][-r <参考文件或目 录>][-t <日期时间>] [--help]　　 [--version][文件或目录...] 或 touch [-acfm][--help][--version][日期时 间][文件或目录...]
补充说明：使用touch指令可更改文件或目录的日期时间，包括存取时间和更改时间。
参　　数：
　-a或–time=atime或–time=access或–time=use 　只更改存取时间。
　-c或–no-create 　不建立任何文件。
　-d<时间日期> 　使用指定的日期时间，而非现在的时间。
　-f 　此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题。
　-m或–time=mtime或–time=modify 　只更改变动时间。
　-r<参考文件或目录> 　把指定文件或目录的日期时间，统统设成和参考文件或目录的日期时间相同。
　-t<日期时间> 　使用指定的日期时间，而非现在的时间。

例：touch test.txt （注：Linux下没有文件后缀名区分文件类型之说，系统文件类型只有可执行文件和不可执行文件）

-------------------------------------------------------------------------------------------------------------------------------------------

创建文件或文件夹的方式

1.　　touch命令

2.　　vi命令

3.　　mkdir命令
---------------------
linux中的文件权限chmod

chmod 777 文件
chmod -R 777 文件夹
Linux系统中，每个用户的角色和权限划分的很细致也很严格，每个文件（目录）都设有访问许可权限，利用这种机制来决定某个用户通过某种方式对文件（目录）进行读、写、执行等操作

操作文件或目录的用户，有3种不同类型：文件所有者、群组用户、其他用户。最高位表示文件所有者的权限值，中间位表示群组用户的权限值，最低位则表示其他用户的权限值，所以，chmod 777中，三个数字7分别对应上面三种用户，权限值都为7。

文件或目录的权限又分为3种：只读、只写、可执行。

权限	权限数值	二进制	具体作用
r	4	00000100	read，读取。当前用户可以读取文件内容，当前用户可以浏览目录。
w	2	00000010	write，写入。当前用户可以新增或修改文件内容，当前用户可以删除、移动目录或目录内文件。
x	1	00000001	execute，执行。当前用户可以执行文件，当前用户可以进入目录。


依照上面的表格，权限组合就是对应权限值求和，如下：

7=4+2+1 读写运行权限

5=4+1 读和运行权限

4=4 只读权限

chmod 754 filename就是将filename文件的读写运行权限赋予文件所有者，把读和运行的权限赋予群组用户，把读的权限赋予其他用户。

------------------------------------------------------------------------------------------
Java类初始化顺序：
　　这是所有情况的类初始化顺序，如果实际类中没有定义则跳过：
父类静态变量——父类静态代码块——子类静态代码块——父类非静态变量——父类非静态代码块——父类构造函数——子类非静态变量——子类非静态代码块——子类构造函数
==========================================================================================================================
一、Docker是什么
Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。
Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心复杂环境问题。
总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。

二、Docker容器与传统虚拟机技术的特性对比

三、Docker的优势
更快速的交付和部署
Docker在整个开发周期都可以完美的辅助你实现快速交付。Docker允许开发者在装有应用和服务本地容器做开发。可以直接集成到可持续开发流程中。
例如：开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间。
高效的部署和扩容
Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。
Docker的兼容性和轻量特性可以很轻松的实现负载的动态管理。你可以快速扩容或方便的下线你的应用和服务，这种速度趋近实时。
更高的资源利用率
Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而Docker 只需要启动 10 个隔离的应用即可。
更简单的管理
使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。

四、Docker版本
Docker 是一个开源的商业产品，有两个版本：社区版（Community Edition，缩写为 CE）和企业版（Enterprise Edition，缩写为 EE）。
Docker Community Edition（CE）适合希望开始使用Docker并尝试使用基于容器的应用程序的个人开发人员和小型团队。
Docker Enterprise Edition（EE）专为企业开发和IT团队而设计，他们可以在生产中大规模构建，发布和运行业务关键型应用程序。


五、系统版本及内核要求
要求内核大于3.0的以下三个版本64位
Bionic 18.04 (LTS)
Xenial 16.04 (LTS)
Trusty 14.04 (LTS)

六、Docker安装
#卸载旧版本(如果安装过旧版本的话)
$ sudo apt-get remove docker docker-engine docker.io
#确保 apt-get 包更新到最新
$ sudo apt-get update
# 安装
$ sudo apt-get install\ apt-transport-https\ ca-certificates\ curl\ software-     properties-common
$ sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo add-apt-repository\ "deb [arch=amd64] 
https://download.docker.com/linux/ubuntu\ $(lsb_release -cs)\ stable”
$ sudo apt-get update
$ sudo apt-get install docker-ce

Image、Container、Repository

七、Image（镜像）文件
Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。
image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形成你的 image。
image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般应该尽量使用现有的 image 文件，而不是自己制作。即使要定制，也应该基于通用的 image 文件进行add，而不是从零开始制作。
#查找镜像
$ sudo docker search <NAME>
#拉取镜像默认为latest
$ sudo docker pull <images-name>
#列出本机所有的镜像文件
$ sudo docker images
#删除镜像文件
$ sudo docker rmi <image-id>
#commit镜像
$ sudo docker commit [option] CONTAINER [REPOSITORY[:TAG]]
-a：提交镜像作者
-c：使用Dockerfile指令创建镜像
-m：提交说明
-p：commit时暂停容器
#查看镜像元数据
$ sudo docker inspect <image-id>

八、Container（容器）
容器(container)由image文件生成的实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。
#列出本机正在运行的容器
$ sudo docker ps
#列出本机所有的容器，包括终止运行的容器
$ sudo docker ps -a
上面命令的输出结果之中，包括容器的 ID。很多地方都需要提供这个 ID

#启动容器
$ sudo docker start <container>
#终止容器
$ sudo docker stop <container>
#重启容器
$ sudo docker restart <container>
注意：终止运行的容器文件，依然会占据硬盘空间
#删除容器
$ sudo docker rm <container>
docker run命令会从 image 文件，生成一个正在运行的容器实例。（注意：docker container run命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的docker image pull命令并不是必需的步骤。）
#以我们现有的容器部署命令示例
$ sudo docker run --name $image_name --log-opt max-size=10m \
-p $container_port:$container_port \
--network $network \
-v /var/log/$image_name:/application/logs \
-e SPRING_REFERENCE=test \
-e SPRING_SERVICE=test \
-e SPRING_PROFILE=test \
-d harbor.emc.top/test-fota/$image_name:latest”
-i: 以交互模式运行容器，通常与 -t 同时使用；
-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；
#进入容器
$ sudo docker exec -it <container> /bin/bash
#查看容器元数据
$ sudo docker inspect <container>
docker inspect 参数及作用可以自己去了解一下，另外可以结合grep、awk查找出需要的元数据。
例如：查看所有运行容器的IP地址
$ sudo docker inspect -f '{{.Name}} - {{.NetworkSettings.IPAddress }}' $(docker ps -aq)

九、Dockerfile 文件
学会使用 image 文件以后，接下来的问题就是，如何可以生成 image 文件？如果你要推广自己的软件，势必要自己制作 image 文件。
这就需要用到 Dockerfile 文件。它是一个文本文件，用来配置 image。Docker 根据 该文件生成二进制的 image 文件。
下面通过一个实例，演示如何编写 Dockerfile 文件。
FROM  node:8.4
COPY  . /app
WORKDIR  /app
RUN  npm install --registry=https://registry.npm.taobao.org
EXPOSE  3000
上面一共五行，含义如下。
FROM node:8.4：该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。
COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。
WORKDIR /app：指定接下来的工作路径为/app。
RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。
EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。
#创建镜像
$ sudo docker build -t [imagename:tag] .
$ sudo docker build -t [imagename:tag] -f  [dockerfile-path]

十、Docker-Compose
1. docker-compose 是什么？
docker-compose 是一个用来把 docker 自动化的东西。有了 docker-compose 你可以把所有复杂的 docker 操作全都一条命令，自动化的完成。
2. 为什么要用 docker-compose，它解决了什么？
用通俗的语言来说，我们平时操作 docker 还是很原始的一系列动作，你手动使用 docker 的动作可以拆分成：
找到一个系统镜像 // docker search
拉取一个镜像  // docker pull
运行镜像 // docker run -d -it 你的镜像
略..
这是最小的动作， 如果你要映射硬盘，设置nat网络或者桥接网络，等等…你就要做更多的 docker 操作， 这显然是非常没有效率的。
但是我们写在 docker-compose.yml 里面就很好了。 你只需要写好后只运行一句：
docker-compose up -d
一切都是那么的简单。
3. 安装Compose
在安装compose之前，要确保已经安装了docker1.3或以上版本 
sudo curl -L 
https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose 
sudo chmod +x /usr/local/bin/docker-compose  
CLI 说明（docker-compose 命令）
build 创建或者再建服务 服务被创建后会标记为project_service(比如composetest_db)，如果改变了一个服务的Dockerfile或者构建目录的内容，可以使用docker-compose build来重建它
help 显示命令的帮助和使用信息
kill 通过发送SIGKILL的信号强制停止运行的容器，这个信号可以选择性的通过，比如： docker-compose kill -s SIGKINT
logs 显示服务的日志输出
port 为端口绑定输出公共信息
ps 显示容器
pull 拉取服务镜像
rm 删除停止的容器
run 在服务上运行一个一次性命令，比如： docker-compose run web python manage.py shell
scale 设置为一个服务启动的容器数量，数量是以这样的参数形式指定的：service=num，比如： docker-compose scale web=2 worker=3
start 启动已经存在的容器作为一个服务
stop 停止运行的容器而不删除它们，它们可以使用命令docker-compose start重新启动起来
up 为一个服务构建、创建、启动、附加到容器 
docker-compose.yml命令说明
Image 标明image的ID，这个image ID可以是本地也可以是远程的，如果本地不存在，Compose会尝试去pull下来
image: ubuntu  
image: orchardup/postgresql  
image: a4bc65fd  

build 该参数指定Dockerfile文件的路径，该目录也是发送到守护进程的构建环境，Compose将会以一个已存在的名称进行构建并标记，并随后使用这个image
build: /path/to/build/dir  

links 连接到其他服务中的容器，可以指定服务名称和这个链接的别名，或者只指定服务名称
links:  
 - db  
 - db:database  
 - redis 
此时，在容器内部，会在/etc/hosts文件中用别名创建一个条目，就像这样：
172.17.2.186  db  
172.17.2.186  database  
172.17.2.186  redis

ports 暴露端口，指定两者的端口（主机：容器），或者只是容器的端口（主机会被随机分配一个端口）ports:  
 - "3000"  
 - "8000:8000"  
 - "49100:22"  
 - "127.0.0.1:8001:8001"  

expose 暴露端口而不必向主机发布它们，而只是会向链接的服务（linked service）提供，只有内部端口可以被指定
expose:  
 - "3000"  
 - “8000"

volumes 挂载路径作为，可以选择性的指定一个主机上的路径（主机：容器），或是一种可使用的模式（主机：容器：ro）
volumes_from:  
 - service_name  
 - container_name  
 
environment 加入环境变量，可以使用数组或者字典，只有一个key的环境变量可以在运行Compose的机器上找到对应的值，这有助于加密的或者特殊主机的值
environment:  
  RACK_ENV: development  
  SESSION_SECRET:  
environments:  
  - RACK_ENV=development  
  - SESSION_SECRET  

env_file 从一个文件中加入环境变量，该文件可以是一个单独的值或者一张列表，在environment中指定的环境变量将会重写这些值
env_file:  
  - .env  
RACK_ENV: development  

net 网络模式，可以在docker客户端的--net参数中指定这些值
net: "bridge"  
net: "none"  
net: "container:[name or id]"  
net: "host" 

docker-compose.yml示例
version: '2'

networks:
    monitor:
        driver: bridge

services:
    prometheus:
        image: prom/prometheus
        container_name: prometheus
        hostname: prometheus
        restart: always
        volumes:
            - /Users/caizh/fsdownload/prometheus.yml:/etc/prometheus/prometheus.yml
            - /Users/caizh/fsdownload/node_down.yml:/etc/prometheus/node_down.yml
            - /Users/caizh/fsdownload/memory_over.yml:/etc/prometheus/memory_over.yml
            - /Users/caizh/fsdownload/record_rule.yml:/etc/prometheus/record_rule.yml
        ports:
            - "9090:9090"
        networks:
            - monitor

    alertmanager:
        image: prom/alertmanager
        container_name: alertmanager
        hostname: alertmanager
        restart: always
        volumes:
            - /Users/sf/fsdownload/config.yml:/etc/alertmanager/config.yml
        ports:
            - "9093:9093"
        networks:
            - monitor

    grafana:
        image: grafana/grafana
        container_name: grafana
        hostname: grafana
        restart: always
        ports:
            - "3000:3000"
        networks:
            - monitor

十一、doker和主机通信
这里先要来说一下docker网络的四种方式：
Host模式
Container模式
None模式
Bridge模式

1. Host模式
Host 模式并没有为容器创建一个隔离的网络环境。该模式下的Docker 容器会和Host宿主机共享同一个网络namespace， Docker Container。可以和宿主机一样，使用宿主机的eth0，实现和外界的通信。
Host模式特点包括：
容器没有隔离的 network namespace
容器的 IP 地址同 Docker host 的 IP 地址
注意：容器中服务端口号不能与Host宿主机上已经使用的端口号相冲突
host 模式能够和其它模式共存

2. Container模式
Container网络模式是 Docker 中一种较为特别的网络的模式。处于这个模式下的 Docker 容器会共享其他容器的网络环境，因此，至少这两个容器之间不存在网络隔离，而这两个容器又与宿主机以及除此之外其他的容器存在网络隔离。

3. None模式
None 网络就是什么都没有的网络。挂在这个网络下的容器除了 lo，没有其他任何网卡。需要我们自行去配置。

4. Bridge模式
Docker 容器默认使用Bridge模式的网络。Docker的Bridge模式和VM虚拟机的Bridge模式不同，虽然也叫Bridge，但实质上类似于VM的NAT模式。

原理是在宿主机上虚出一块网卡bridge0，然后所有容器会桥接在这块网卡的网段上。
默认情况下容器能访问外部网络，但外部网络无法访问容器，需要通过暴露容器端口的方式（docker run -p）让外部网络访问容器内的服务。
===========================================================================================================================================
CENTOS7.5安装docker；
1、由于docker是必须在内核版本在3.1以上的linux系统上安装；

uname -r ：查看当前linux的的内核版本；

2、yum install docker -y    ：在根目录执行安装docker命令；

3、docker -v      ：查看docker的版本号；

 修改docker的镜像源：
 1、修改/etc/docker/daemon.json文件
     vi /etc/docker/daemon.json
 2、
 然后加入代码
	{
	  "registry-mirrors": ["https://registry.docker-cn.com"]
	}
	
--------------安装docker的步骤：------------------------------------------------------------------------------------
1、添加yum源。
yum install epel-release -y
yum clean all
2、安装yum-util。
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
3、设置docker yum源。
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
4、安装并运行Docker。
sudo yum install docker-ce -y
systemctl enable docker
systemctl start docker
5、检查安装结果。
docker --version
回显如下类似信息，表示Docker安装成功。
Client: Docker Engine - Community
Version: 19.03.13
----------------------------------------------------------------------------------------------------------------

 4、systemctl start docker    ：启动docker；
 
 5、systemctl stop docker     :停止docker；
 
 6、systemctl enable docker   :将docker安装设置为开机启动；
 
 7、docker search mysql       ：搜索MySQL镜像；
 
 8、docker pull mysql         ：从docker的公共仓库中拉取MySQL的默认镜像；
 
 9、docker images             ：查看当前docker中是否安装了哪些镜像；
 
 10、docker rmi (images ID)   ：删除镜像（镜像ID）；
 
 11、docker ps				  ：查看安装并启动的镜像；
 
 12、docker ps -a             ：查看所有的已启动的镜像实例；
 
 13、docker rm  (images id(镜像实例的ID)) --> 删除一个镜像实例时，必须停止要删除的镜像实例：  
 
 14、docker run --name 指定的实例名称启动一个镜像实例：
 
     docker restart 容器ID
 
 15、docker run -d(标识后台运行) -p(指定映射的端口号(主机端口号:容器内部端口号))
		(mysql(必填指的是容器的REPOSITORY(docker images命令查出来的第一列)))    -->启动一个完成端口映射的镜像实例：
 
 16、docker logs -f mysql(容器运行的ID)   实时查看日志：

     docker logs mysql ; 查看正在运行的镜像实例日志：
进入docker容器：
docker exec -it 55b1faff3521 bash
	 
 17、docker上启动MySQL镜像实例：docker run --name MySQL3306 -e MYSQL_ROOT_PASSWORD=1234567 -d mysql
 
 18、docker上启动带映射的MySQL镜像实例：docker run -p 3307:3306 --name MySQL3306 -e MYSQL_ROOT_PASSWORD=1234567 -d mysql
 
  -p 3307:3306 --> 含义linux服务器与docker端口映射关系：  前面的端口号(3307)是可以通过公网记性访问到端口，后面的端口号(3306)是安装的镜像服务默认的端口号
 
 docker中启动springboot的命令：
 
 docker run -p 8046:8036 --name evening8046 -d springboot/hulunbuir-evening 
 
 
 19、docker上启动带映射并设置字符集的MySQL镜像实例：
	docker run -p 3308:3306 --name mysql3308 -e MYSQL_ROOT_PASSWORD=1234567 -d mysql --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
	#进入MySQL镜像实例容器中
	docker exec -it MySQL3306(镜像名称) bash
	docker exec -it 55b1faff3521 bash
	#退出容器：
	exit;
	#登录mysql
	mysql -u root -p
	ALTER USER 'root'@'localhost' IDENTIFIED BY '1234567';
	客户端在使用root连接的时候会出现：client does not support authentication protocol requested by server;consider upgrading mysql client 
	#添加远程登录用户
	CREATE USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '1234567';
	GRANT ALL PRIVILEGES ON *.* TO 'root'@'%';
	#程序中的应用是：
	 IP地址是公网的IP地址
	#账号分别是
	 root:1234567
	 qjyn1314:1234567
	#程序在链接数据库(docker默认安装的是mysql最新版本)时出现的问题：
	 1、Could not retrieve transation read-only status server
		解决：
		 将pom文件中的MySQL链接的的驱动换成Maven仓库中最新版本，
			<dependency>
				<groupId>mysql</groupId>
				<artifactId>mysql-connector-java</artifactId>
				<version>8.0.13</version>
			</dependency>
	 2、在MySQL5.7之后默认不开启，group by的函数的问题：
		SELECT @@GLOBAL.sql_mode;
		SELECT @@SESSION.sql_mode;
		set sql_mode ='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';


select Host,User from mysql.user;

create user admin identified by '123456';

grant all privileges on *.* to 'admin'@'%' with grant option;


 20、docker安装jenkins
		#搜索jenkins
		docker search jenkins
		#拉取jenkins镜像
		docker pull jenkins
		#创建主机的jenkins文件存储路径
		mkdir /usr/local/jenkins
		chown -R 1000:1000 /usr/local/jenkins
		#运行带映射端口的jenkins，并指定文件配置路径
		docker run -p 8080:8080 -p 50000:50000 -v /usr/local/jenkins:/var/jenkins_home -d jenkins
		docker run -d --name myjenkins -p 8080:8080 -p 50000:50000 -v /usr/local/jenkins/data:/var/jenkins_home jenkins
		#查看是否启动成功
		docker ps -a 
		#查看日志
		docker logs jenkins的启动后的容器ID
		#得到密码
		Please use the following password to proceed to installation:
		d406a25e9e2c49b4ad42a9205cedba80    #此字符串为jenkins的admin密码；
		This may also be found at: /var/jenkins_home/secrets/initialAdminPassword
		然后紧接着进行操作。
 
sudo docker run -itd -p 8060:8080 -p 50012:50000 --name jenkins --privileged=true  -v /usr/local/jenkins/:/var/jenkins_home jenkins
 
ps -ef | grep tongke-dashboards | grep -v grep | cut -c 9-15 | xargs kill -s 9
 进入容器：
docker exec -it 55b1faff3521 bash
---------

export JAVA_HOME=/usr/java/jdk1.8.0_221-amd64
export CLASSPATH=$JAVA_HOME/lib/
export PATH=$PATH:$JAVA_HOME/bin
export PATH JAVA_HOME CLASSPATH




wget https://dl.halo.run/release/halo-1.2.0.jar -O halo-latest.jar

/halo/halo-latest.jar
wget https://dl.halo.run/release/halo-1.3.2.jar -O halo-latest.jar

------------------------------------------

3017185d11384bcaa72810c65b2655d6
docker pull jenkinsci/blueocean

docker run -p 10000:8080 jenkinsci/blueocean

-->docker上启动jenkins命令：

docker run --name jenkins_blueocean -d -p 10000:8080 -p 50000:50000 -v jenkins-data:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock  jenkinsci/blueocean
  
docker run \
  -u root \
  --rm \
  -d \
  -p 8080:8080 \
  -p 50000:50000 \
  -v jenkins-data:/var/jenkins_home \
  -v /var/run/docker.sock:/var/run/docker.sock \
  jenkinsci/blueocean
  
  docker run --name jenkins_blueocean  -u root -d -p 8088:8080 -p 50000:50000 -v jenkins-data:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock jenkinsci/blueocean
  
docker run --name jenkins_blueocean  -u root -d -p 8088:8080 -p 50000:50000 -v jenkins-data:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock -v /usr/java/jdk1.8.0_221-amd64/bin/java:/usr/java/jdk1.8.0_221-amd64/bin/java -v /usr/java/jdk1.8.0_221-amd64:/usr/java/jdk1.8.0_221-amd64 -v /usr/maven/maven-3.6.3:/usr/maven/maven-3.6.3 -v /usr/bin/git:/usr/bin/git jenkinsci/blueocean

java -jar tongke-dashboards.jar --spring.profiles.active=tangpiao-pro 

 
---------------------------------------------------


然后重启容器：
docker restart 容器ID 
 	
 21、docker安装redis
		#搜索redis
		docker search redis
		#拉取redis
		docker pull redis
		#运行带参数的redis，并指定密码
		docker run --name redis6666 -p 6666:6379 -d redis --requirepass "1234567"
		#查看运行成功的redis
		docker ps -a
		程序中应用的：ip地址是，服务器的公网ip，端口号是6666。
	
 22、docker安装zookeeper
		#搜索zookeeper
		docker search zookeeper
		#拉取zookeeper
		docker pull zookeeper
		#运行带参数的zookeeper
		docker run --name zookeeper4181 --restart always -p 4181:2181 -d zookeeper
		docker run --name zookeeper4182 --restart always -p 4182:2181 -d zookeeper
		docker run --name zookeeper4183 --restart always -p 4183:2181 -d zookeeper
		程序中的使用:dubbo配置文件中的ip地址以及端口号是：47.104.78.115:4181
		这样只能用于测试环境
		
 23、docker安装rabbit
		#搜索rabbit
		docker search rabbit
		#拉取rabbit
		docker pull rabbit 
		#运行带参数的rabbit
		docker run -d --hostname my-rabbit5672 --name rabbit5672 -p 5672:5672 rabbitmq
		#查看实时日志：docker logs -f 正在运行的容器ID
		47.104.78.100:5672
				 
		docker安装带管理页面的rabbitmq(rabbitmq:management)
		#搜索rabbitmq:management
		docker search rabbitmq:management
		#拉取rabbitmq:management
		docker pull rabbitmq:management
		#运行带管理界面的rabbitmq:management
		docker run -d --name rabbitmqAndManager --publish 5671:5671 --publish 5672:5672 --publish 4369:4369 --publish 5674:25672 --publish 5675:15671 --publish 5676:15672 rabbitmq:management
		#访问管理页面：
		47.104.78.115:5676   即可打开rabbitmq的管理页面
		默认的登录账户密码：guest：guest
		springboot的配置文件中使用 47.104.78.115 ： 5672
		 
 24、docker安装mongodb
		#搜索MongoDB
		docker search mongo
		#拉取mongo
		docker pull mongo
		#运行带参数的mongo
		docker run -p 27017:27017 -v /usr/local/mongo/data:/data/db --name mongodb27017 -d mongo
		#查看实时日志：
		docker logs -f 正在运行的容器ID
		#进入 mongo 交互模式
		docker exec -it <CONTAINER NAME> mongo admin
		docker exec -it mongodb27017 mongo admin
---------------------------------------------------------------------
25、docker中安装nacos1.3.1
参考：
1、https://www.cnblogs.com/binz/p/12295346.html
2、https://www.jianshu.com/p/e053f016371a
1.docker search nacos
2.docker pull nacos/nacos-server:1.3.1
创建文件夹：
/usr/nacos/properties/custom.properties

custom.properties 文件的内容：management.endpoints.web.exposure.include=*
/usr/nacos/logs

3.docker run -d -p 8848:8848 -e MODE=standalone -v /usr/nacos/properties/custom.properties:/home/nacos/init.d/custom.properties -v /usr/nacos/logs:/home/nacos/logs --restart always --name nacos nacos/nacos-server:1.3.1

---------------------------------------------------------------------
26、docker中安装seata
 
启动命令： 

docker run --name seata-server -p 8091:8091 -d seataio/seata-server:latest 
 
将两个文件cp到docker容器中：

docker cp 本地路径 容器长ID:容器路径

docker cp /usr/local/seata/file.conf 7bce396b2b11:/seata-server/resources

docker cp /usr/local/seata/registry.conf 7bce396b2b11:/seata-server/resources
 
---------------------------------------------------------------------
	
25、docker上安装superset：

1、mkdir opt\docker\superset
2、docker run -d -p 8087:8088 -v /opt/docker/superset:/home/superset amancevice/superset
3、docker exec -it 49fc1ef8c6ec fabmanager create-admin --app superset
4、docker exec -it 49fc1ef8c6ec superset db upgrade
5、docker exec -it 49fc1ef8c6ec superset init
6.1、docker exec -it 49fc1ef8c6ec superset run      控制台运行
6.2、docker exec -it 49fc1ef8c6ec superset run &    在后台运行

7、进入容器：docker exec -it 49fc1ef8c6ec bash

从容器拷贝文件到宿主机
//将container id为4db8edd86202的容器内elasticsearch.yml文件拷贝到宿主机指定目录下：
docker cp 49fc1ef8c6ec:/usr/share/elasticsearch/config/elasticsearch.yml /home/haopeng/es

从宿主机拷贝文件到容器
docker cp /opt/docker/iciyun_images/favicon.png 49fc1ef8c6ec:/usr/local/lib/python3.6/site-packages/superset/static/assets/images/

docker cp /opt/docker/iciyun_images/superset.png 49fc1ef8c6ec:/usr/local/lib/python3.6/site-packages/superset/static/assets/images/

docker cp /opt/docker/iciyun_images/superset-logo@2x.png 49fc1ef8c6ec:/usr/local/lib/python3.6/site-packages/superset/static/assets/images/

搭建superset的开发环境：
 
pip install F:\DevelopmentInstall\python_INSTALL\sasl-0.2.1-cp37-cp37m-win_amd64.whl

set FLASK_APP=superset 
flask fab create-admin
python superset db upgrade
python superset load_examples

postgresql://postgres:adm1234@182.92.148.105:5432/cy_tongke

安装虚拟环境
https://blog.csdn.net/jery_cheer/article/details/78259795

https://www.jianshu.com/p/20cbf6902ef7

从代码上安装superset
https://www.jianshu.com/p/2ccfd6669cb1

flask fab create-admin --app superset 


fabmanager create-admin --app superset
 
如何阅读：
如何阅读一本书
高倍速阅读法
张凯：怎样成为快速阅读的高手
超级快速阅读法
秋叶 如何高效读懂一本书
如何高效阅读
王者速读法 
=================================================================================================================================
sudo grep mysql_root_passwd /root/env.txt
mysql_root_passwd:86D0302e5ccb
=================================================================================================================================
张孝祥
javaWeb马士兵

java类加载：
1、java虚拟机使用每一个类的第一件事请就是将该类的字节码装载进来，装载类字节码的功能是由类装载器完成的，
	   类装载器负责根据一个类的名称来定位和生成类的字节码数据后返回给java虚拟机
2、类加载器本身也是一个java类，java虚拟机也允许开发人员编写自己的类装载器，以便通过其他各种特殊方式来产生类字节码。
3、不管类装载器采用什么方式，只要能够在内存中制造出给java虚拟机调用类字节码即可，所以，把类装载器描述为类字节码的制造器更容易让人理解。
4、当一个类被加载后，java虚拟机将其编译为可执行代码存储在内存中，并将索引信息存储进一个hashtable中，其索引关键字为与之相对应的类名。
java虚拟机中，首先会在hashtable中查找java类字节码，若是找不到，则进行编译

5、java程序中的类本身也是一种事物，他也可以用一个java类来描述，这个特殊的类名就叫class。
类装载器装载某各类的字节码的过程就是在创建class类的实例对象，这个class类的实例对象封装的内容正好是当前加载的类的字节码数据。

获取某各类的字节码数据的class实例对象，可以使用下面三种方式：
1.类名.class  2.对象.getClass() 3.Class.forName("类名")  

java类库中提供了一个java.lang.ClassLoader 类作为类装载器的基类，java虚拟机和程序都调用classLoader类的loadClass方法来加载类，
ClassLoader是一个抽象类，真正的类装载器必须是classLocader的子类，
Class类中定义了一个getClassLoader方法，用于返回他所描述的类的而来加载器对象，这个返回对象的类型是classLoader。

类装载器的基本策略：
一个类装载器本身也是一个java类，所以类装载器也需要被另外一个类装载器装载
java虚拟机中内嵌了一个称为bootstrap的类装载器（是特定于操作系统的本地代码实现的，属于java虚拟机的内核，不用类装载器装载），
bootstrap类装载器负责加载java核心包中的类，这些类的class.getClassLoader犯法返回值为null，表示是bootstrap类装载器。

在java核心包中，
ExtClassLoader类装载器负责加载存放在JAVA_HOME/jre/lib/ext目录下的jar包中的类
AppClassLoader负责加载应用程序启动执行类

一个java虚拟机中的所有类装载器采用具有父子关系的属性结构进行组织，在实例化每个类装载器对象时，
需要为其执行一个父级类装载器对象，如果没有执行的话，则以ClassLoader.getSystemClassLoader()方法返回的系统类装载器作为其父级类装载器对象

系统类装载器通常被设置为启动应用程序的AppClassLoader，可以通过java.system.class.loader系统属性来将系统类装载器设置为其他类装载器，WxtClassLoader是AppClassLoader父级类装载器，ExtClassLoader没有父级类装载器。

每个ClassLoader本身只能分别加载特定位置和目录中的类，但是ClassLoader被设计成了一个委托模式，是的某一个ClassLoader可以委托他的父级装载器去加载类，从而让应用程序可以借助某一个自己的ClassLoader去多个位置和目录中进行类的加载。

***************************************
当要加载一个类时，ClassLoader的LoadeClass方法先查找这个类的是否已被加载，
如果没有加载则委托其父级类装载器去加载这个类，
	如果父级的类装载器无法装载这个类，
		则子级类装载器才调用自己内部的findClass方法去进行真正的加载。
		其委托过程会一直追溯到Bootstrap类装载器，
	如果委托过程中的所有类装载器，都不能完成类的装载，
	最终就会报告ClassNotFoundException异常。
****************************************

一个类装载器只能创建某个类的一份字节码数据，即只能为某个类创建一个与之对应的Class实例对象。

在一个java虚拟机中可以存在多个类加载器，每个类加载器都拥有自己的名称空间，对于同一个类，每个类加载器都可以创建出它的一个Class实例对象。

****************************************
采用委托模式的原因：
避免了一个java虚拟机中的多个类加载器为同一个类创建多份字节码数据的情况，
只要开发人员自定义的类装载器不覆盖ClassLoader的LoaderClass方法，而是覆盖其findClass方法，这样就可以继续采用委托模式。
当loadClass没有加载成功的时候，就会使用findClass方法，进行具体的加载
****************************************

每个类装载器是不能实现数据共享的。

线程中的类加载器：

如果在类A中使用new 关键字创建类B，java虚拟机将使用加载类A的类装载器来加载类B。
如果在一个类中调用Class.forName方法的一个参数来指定类B的类装载器。
如果没有指定该参数，则使用加载房钱类的类装载器。

每个运行中的线程都有一个关联的上下文类加载器，可以使用
Thread.setContextClassLoader()方法设置线程的上下文类装载器。

每个线程默认的上下文类装载器是其负线程的上下文类装载器，而主线程的类装载器初始被设置为ClassLoader.getSystemClassLoader()方法返回的系统类加载器

当前线程中运行的代码需要使用某个类时，它使用上下文类装载器来装载这个类，上下文类装载器首先会委托他的父级类装载器来装载这个类， 如果父级类装载器无法装载时，上下文类装载器才自己进行装载。

TOMCAT中的类装载器：

System即系统类装载器，通常情况下就是AppClassLoader，负责加载CLASSPATH环境变量，只包含tool.jar、bootatarp.jar 的两个包。

common类装载器负责从CLASS_HOME/common/classes中的.class文件
和CLASS_HOME/common/lib中的jar包加载类。

catalina类装载器(tomcat内核)负责从CLASS_HOME/service/classes中的.class文件

shared类装载器负责从CLASS_HOME/

============================

 maven是什么：
 是构建工具，依赖管理工具，项目信息管理工具

 maven的优点--选择maven的原因：
 1、简单，maven暴露了一组一致、简洁的操作接口，使用maven成熟的、稳定的组件可以简化构建系统的复杂度
 2、交流与反馈，
 3、测试驱动开发，
 4、十分钟构建，
 5、持续集成，
 6、富有信息的工作区，

maven的坐标，依赖，仓库，周期，插件：
核心pom中的坐标：
代码第一行是xml开头的，指定了xml文档的版本和编码方式
标签project是所有pom的根元素，声明啦pom的相关的命名空间和xsd元素，这个标签不是必须的，但是可以让第三方的编译器给我们标签提示
标签modelVersion指定了当前pom的版本，对于maven2和maven3来说只能是：4.0.0
标签groupId定义了当前maven项目隶属于的实际项目
标签artifactId定义了实际项目中的一个maven项目（模块），推荐做法是，将实际项目名称的前缀作为artifactId的前缀
标签version定义了当前maven项目的所处的版本
标签packaging定义当前maven项目的打包方式，jar、war、pom
标签classfier定义帮助当前maven项目构建输出的一些附属构件
标签name定义了当前maven项目的名称，这个标签不是必须的，但是为了对于用户更为友好的项目名称，推荐为每一个maven项目添加名称
注意：
groupId、artifactId、version是必须定义的
packaging是可选的，默认是jar包
classfier是不能直接定义

 maven的依赖：
 引入的依赖方法：
 所需要依赖的jar包的坐标是放在depencendy标签内
 groupId、artifactId、version是必须的
 type是依赖的类型，默认是jar
 scope：依赖的范围
 optional：标记依赖是否可选
 exclusions：用来排除传递性依赖

 引入依赖的范围（控制项目所使用的classpath以及需要的class文件）：

 compile：编译依赖范围，若没有指定则默认使用该依赖范围，对于编译、测试、运行、三种classpath都有效，例子：spring-core，什么时候都需要这个依赖
 test：测试依赖范围，对于测试的classpath有效，在编译、运行项目的时无效，例子，典型的JUnit测试
 provided：已提供依赖范围，对于编译和测试的classpath有效，在运行项目时无效，例子，servlet-api
 runtime：运行时依赖范围，对于测试和运行的classpath有效，在编译项目的时候无效，例子，典型的jdbc驱动实现
 system：系统依赖范围，此依赖与三种classpath的关系和provided的依赖范围完全一致，但是对于此依赖范围时，必须通过systemPath标签显示的指定依赖文件的路径，
         由于此依赖不是通过maven仓库解析的，而是往往与本机系统绑定，可能造成构建的不可移植，应当谨慎使用
 import：导入依赖范围，此依赖范围不会对三种classpath产生实际影响

 maven传递性依赖机制：
 引入的A依赖于B，则为传递依赖
 间接依赖：
 引入的A依赖于B，B依赖于C，则C是A的间接依赖

 maven依赖调解原则：
 1、路径最近者优先
 2、第一声明者优先

 查看maven已解析依赖， mvn dependency:list
 查看maven的依赖树，mvn dependency:tree
 分析maven的依赖，mvn dependency:analyze  只会分析编译的主代码和测试代码需要用到的依赖，一些执行测试和运行时的依赖他发现不了的

 maven可选依赖，则是A依赖于B，B依赖于C和D，这个时候，依赖将不会传递，即C和D依赖不会影响到A，这种现象就是可选依赖，A选择C和D哪个依赖，
          C和D依赖只会对B产生影响，当实际应用中A所需要的依赖是C，那么就需要将C这个依赖添加到A的pom文件中

 maven仓库私服：
  节省自己外网的带宽，加速maven构建，部署第三方构建，提高稳定性、增强控制，降低中央仓库的负荷

 maven周期：
 maven的生命周期就是为了对所有的构建过程进行抽象和统一
 maven的生命周期是抽象的，也就意味着生命周期本身不做任何实际的工作，实际的任务（编译源码，清除打包的文件）是由插件完成的，
 maven的生命周期包含了更多的步骤和更复杂的逻辑，但他们的理念都相同，生命周期是抽象了各个构建的步骤，定义了他们的次序，但是没有提供具体的实现，那么这个步骤是谁来完成的，肯定不是开发人员，
 
 maven考虑到了这一点，因此他设计了插件机制，每一个构建步骤绑定了多个插件行为，而且maven为大多数的构建绑定了默认的构建插件，
 若当用户有特殊需求的时候则配置插件的构建行为，甚至自己编写插件
 命令行输入的往往对应了生命周期，

maven拥有三套相互独立的生命周期:
Clean Lifecycle 在进行真正的构建之前进行一些清理工作。 

Default Lifecycle 构建的核心部分，编译，测试，打包，部署等等。

Site Lifecycle 生成项目报告，站点，发布站点。 
=====================================================================================================================================================
=====================================================================================================================================================
 Springboot(1.5.19)的启动原理以及启动步骤(大部分版本的启动方式)：
	1、创建SpringApplication对象，
		1.initialize();方法，
		if (sources != null && sources.length > 0) {
		//保存主配置类
            this.sources.addAll(Arrays.asList(sources));
        }
		//判断当前应用是否是web应用
        this.webEnvironment = this.deduceWebEnvironment();
        //加载MATE/INFO下面的springboot.factories配置的所有ApplicationContextInitializers,(找到自动配置类)并保存。
		this.setInitializers(this.getSpringFactoriesInstances(ApplicationContextInitializer.class));
	    //加载MATE/INFO下面的springboot.factories配置的所有ApplicationListener,(找到监听器)并保存。
        this.setListeners(this.getSpringFactoriesInstances(ApplicationListener.class));
		//从多个配置类中找到带有main方法的主配置类
        this.mainApplicationClass = this.deduceMainApplicationClass();
		
	
	2、运行run方法，
	 public ConfigurableApplicationContext run(String... args) {
        StopWatch stopWatch = new StopWatch();
        stopWatch.start();
        ConfigurableApplicationContext context = null;
        FailureAnalyzers analyzers = null;
        this.configureHeadlessProperty();
		//获取SpringApplicationRunListeners：从类路径下META-INF下获取监听器，
        SpringApplicationRunListeners listeners = this.getRunListeners(args);
        //回调所有的获取SpringApplicationRunListeners的starting()方法，
		listeners.starting();
        try {
			//开启
            ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
            //准备环境并创建：IOC环境，
			ConfigurableEnvironment environment = this.prepareEnvironment(listeners, applicationArguments);
			//创建完成SpringApplicationRunListeners，ApplicationArguments，并打印banner；
            Banner printedBanner = this.printBanner(environment);
			//创建ApplicationContext，根据是否是web应用，利用反射，来创建IOC容器；
            context = this.createApplicationContext();
            new FailureAnalyzers(context);
			//准备上下文环境：将environment保存在ioc中；其中applyInitializers方法里面调用ApplicationContextInitializer的initialize()方法，
			//将初始化器进行回调，将环境都准备好之后，回调的方法：SpringApplicationRunListeners的contextLoaded(),在方法的最后执行；
			this.prepareContext(context, environment, listeners, applicationArguments, printedBanner);
			//刷新容器，初始化ioc容器，同步的并创建安全的容器(如果是web应用还会创建嵌入式的tomcat)，
			//扫描，创建，加载所有组件的地方；(配置类，组件，自动配置)
            this.refreshContext(context);
			//从ioc容器中获取ApplicationRunner和CommandLineRunner，；来进行回调
            this.afterRefresh(context, applicationArguments);
			//所有的SpringApplicationRunListener回调finished，进行启动；
            listeners.finished(context, (Throwable)null);
            stopWatch.stop();
            if (this.logStartupInfo) {
                (new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), stopWatch);
            }
            return context;
        } catch (Throwable var9) {
            this.handleRunFailure(context, listeners, (FailureAnalyzers)analyzers, var9);
            throw new IllegalStateException(var9);
        }
    }
 
=======================================================================================================================================================
 @Null 被注释的元素必须为 null
 @NotNull 被注释的元素必须不为 null(用于基本类型)
 @NotBlank 不能为空，检查时会将空格忽略(用于String类型)
 @NotEmpty 被注释的字符串的必须非空 (用在集合类上面)

 @AssertTrue 被注释的元素必须为 true
 @AssertFalse 被注释的元素必须为 false
 @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值
 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值
 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值
 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值
 @Size(max, min) 被注释的元素的大小必须在指定的范围内
 @Digits(integer=2,fraction=20)//检查是否是一种数字的整数、分数,小数位数的数字。
 @Past 被注释的元素必须是一个过去的日期
 @Future 被注释的元素必须是一个将来的日期
 @Pattern(value) 被注释的元素必须符合指定的正则表达式
 @URL(protocol=,host,port)//检查是否是一个有效的URL，如果提供了protocol，host等，则该URL还需满足提供的条件
 @Valid
 该注解只要用于字段为一个包含其他对象的集合或map或数组的字段，或该字段直接为一个其他对象的引用，
 这样在检查当前对象的同时也会检查该字段所引用的对象

 Hibernate Validator 附加的 constraint
 @CreditCardNumber//对信用卡号进行一个大致的验证
 @Email 被注释的元素必须是电子邮箱地址
 @Length 被注释的字符串的大小必须在指定的范围内
 @Range 被注释的元素必须在合适的范围内

=======================================================================================================================================================