==git学习==
----------------------------------------------------------|
git pull时，需要登录的账户和密码						  |
wangjunming@iciyun.com									  |
Iciyun123												  |
----------------------------------------------------------|
git的命令学习：
git status :查看git提交状态；
git config --list :查看git设置列表；
git checkout 文件名：撤回已修改的文件；
git pull ：将远程仓库的的最新代码clone到本地仓库；
git add 文件名：将文件添加到本地的栈内存中；
git commit -m "注释"；将文件提交到本地仓库中；
git push ：将已经提交到本地仓库的文件，推送到远程仓库；
-------------------------------------------------------------
git status  查看git提交状态；								 
git add '文件名'					                         
git pull 同步到服务器前先需要将服务器代码同步到本地			 
git commit -m "提交本次的注释"； 					         
git push 推送至远程客户端                                    
				                 
多个人同时修改一个类时，更新时会发生冲突，					 
解决方法：					                                 
1、git stash ：将本地中所有的的需要更新的放入git栈中；		 
2、git pull ：更新至最新的代码，					         
3、git stash pop ：将git栈中的文件进行弹栈，				 
4、查看文件中发生冲突的文件，将其中的冲突解决后，进行提交	 
5、git status ：查看当前的哪些文件是需要提交到远程库中的，	 
6、git add ：将发生冲突的文件添加到本地库中，				 
7、git reset ：将不需要修改的文件从本地仓库中撤回，			 
8、git commit -m "提交本次的注释" ，					     
9、git push ：将本地仓库中更新的代码，推送至远程仓库。	     
------------------------------------------------------------|
永久记住git客户端提交代码时输入的账号和密码					 
在命令行输入命令:					                         
前提是已经输入过账号和密码；				            	 
git config --global credential.helper store					 
这一步会在用户目录下的.gitconfig文件最后添加：      		 
[credential] helper = store					                 
通过命令git config --list					            	 
来检查，是否有credential.helper=store这个属性				 
再次打开git客户端，来检查效果；					            
--------------------------------------------------------------
------------------------------------------------
deploy -e 
------------------------------------------------
 
 在多线程的应用场景下：
  
 同步块的锁是：
 --任意的，创建出来的对象实例
 同步函数的锁是：
 --是当前的对象，也就是this
 静态同步函数锁是：
 --因为是静态的，随着类的加载而加载，所以锁是：当前类名.class
 创建线程：继承thread类，复写父类的run方法，start开启线程；
 
 复写run方法的作用
 run方法是用于存储线程所需要执行的自定义代码。
 
 创建继承Thread类的线程，并执行start方法
 start是来开启线程，调用run方法中需要执行的自定义代码，
 
 直接运行run方法就是直接来运行自定义的代码，并没有开启一个线程去执行自定义代码，
				而是跟主线程一样，当前就只有一个主线程在执行，
 
 线程的几种状态：
 被创建（start()）；
 运行（run()）；
 临时状态（sleep(time)）具备执行资格，但是没有执行权，时间一到则开始执行；
 冻结状态（wait()）放弃了执行资格，也可以传参数，时间一到则也开始执行；
 唤醒线程（notify()）,唤醒冻结状态的的线程；
 消亡（stop()，run方法结束）；
 
---------------------------------------------------------------- 
----------------------------------------------------------------
微信进行绑定：
触发aouth2的静默授权，然后获取到code，将code放到回调的url上，
前端将这个code再次请求后台接口，
-->接口中会访问微信的服务器，
换区AccessToken,openid,
再次访问微信的服务器，将用户的基本信息，返回给前端，
前端拿到这个信息之后，用户绑定的时候，将这个用户的基本信息后存储到数据库中；
---------------- ---------------- ---------------- ---------------- 
项目是一个B2B模式的，主要解决的问题是供应商的资金问题，只要两个企业之间有应付账款的订单，系统通过这个订单进行流转，
让供应商更快的拿到资金，解决资金流转慢的问题，流转的业务有，开票，融资，其中用到了第三方的中金支付，cfca的合同协议
其企业主要的功能有，唐票开具、唐票融资、融资复合、兑付计划、资产账户、资金流水、合作企业
在运营端主要的功能有，企业审核，授信管理、授信复核、流转管理、付款计划
微信上的服务号，
我负责的主要模块是，合作企业，授信管理，信息服务，对接cfca的ukey制作和使用，微信公众号

开发环境：
git+maven+jdk1.8+mysql
使用的技术：
springmvc+springboot+mybatis+redis+zeekooper+dubbo+rabbitmq+vue


----------------

*     100 200 400 800 1600
*      1   2   3   4   5
*
*      100若是中，再投就是100；不中，再投就是200；
*      200若是中，再投就是100；不中，再投就是400；
*      400若是中，再投就是100；不中，再投就是800；
*      800若是中，再投就是100；不中，再投就是1600；
*      1600若是中，再投就是100；不中，则止损，再投就是100；

---------------- ---------------- ----------------

LINUX学习：

cat /etc/redhat-release    ：查看Linux的系统版本；

=========================================================================================================================================================== 
CENTOS7.5安装MYSQL:
cat /etc/redhat-release    ：查看Linux的系统版本；
1、进入：/usr/local/mysql  执行命令：wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm
2、rpm -ivh mysql-community-release-el7-5.noarch.rpm
3、yum install mysql-community-server
4、service mysqld restart ：重启MySQL服务；
5、mysql -u root     
6、set password for 'root'@'localhost' =password('1234567');
注意：以上命令执行就是在/usr/local/mysql目录下执行，若是没有该目录，则创建
7、
 远程连接设置
把在所有数据库的所有表的所有权限赋值给位于所有IP地址的root用户。
执行命令：mysql> grant all privileges on *.* to root@'%' identified by '1234567';
如果是新用户而不是root，则要先新建用户
执行命令：mysql>create user 'username'@'%' identified by 'password';  
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '1234567'; 
将设置生效
FLUSH PRIVILEGES;
=========================================================================================================================================================== 
https://www.darknetmarkets.com/ultimate-dark-web-toolbox/   
=====================================================================================================================================================
数据库提供了四种事务隔离级别, 不同的隔离级别采用不同的锁类开来实现. 

在四种隔离级别中, Serializable的级别最高, Read Uncommited级别最低. 

大多数数据库的默认隔离级别为: Read Commited,如Sql Server , Oracle. 

少数数据库默认的隔离级别为Repeatable Read, 如MySQL InnoDB存储引擎 

即使是最低的级别,也不会出现 第一类 丢失 更新问题 .  

1. 脏读(事务没提交，提前读取)：脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 

2. 不可重复读(两次读的不一致) ：是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。例如，一个编辑人员两次读取同一文档，但在两次读取之间，作者重写了该文档。当编辑人员第二次读取文档时，文档已更改。原始读取不可重复。如果只有在作者全部完成编写后编辑人员才可以读取文档，则可以避免该问题。 
3. 幻读 : 是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。例如，一个编辑人员更改作者提交的文档，但当生产部门将其更改内容合并到该文档的主复本时，发现作者已将未编辑的新材料添加到该文档中。如果在编辑人员和生产部门完成对原始文档的处理之前，任何人都不能将新材料添加到文档中，则可以避免该问题。 
4.第一类更新丢失(回滚丢失)： 
  当2个事务更新相同的数据源，如果第一个事务被提交，而另外一个事务却被撤销，那么会连同第一个事务所做的跟新也被撤销。也就是说第一个事务做的跟新丢失了。 
5.第二类更新丢失(覆盖丢失)： 
  第二类更新丢失实在实际应用中经常遇到的并发问题，他和不可重复读本质上是同一类并发问题，通常他被看做不可重复读的特例：当2个或这个多个事务查询同样的记录然后各自基于最初的查询结果更新该行时，会造成第二类丢失更新。因为每个事务都不知道不知道其他事务的存在，最后一个事务对记录做的修改将覆盖其他事务对该记录做的已提交的跟新... 
补充 : 基于元数据的 Spring 声明性事务 : 

Isolation 属性一共支持五种事务设置，具体介绍如下： 

l          DEFAULT 使用数据库设置的隔离级别 ( 默认 ) ，由 DBA 默认的设置来决定隔离级别 . 

l          READ_UNCOMMITTED 会出现脏读、不可重复读、幻读 ( 隔离级别最低，并发性能高 ) 

l          READ_COMMITTED  会出现不可重复读、幻读问题（锁定正在读取的行） 

l          REPEATABLE_READ 会出幻读（锁定所读取的所有行） 

l          SERIALIZABLE 保证所有的情况不会发生（锁表） 

不可重复读的重点是修改 : 
同样的条件 ,   你读取过的数据 ,   再次读取出来发现值不一样了 
幻读的重点在于新增或者删除 
同样的条件 ,   第 1 次和第 2 次读出来的记录数不一样


----------------------------------------------------------
事务传播行为种类

Spring在TransactionDefinition接口中规定了7种类型的事务传播行为，

它们规定了事务方法和事务方法发生嵌套调用时事务如何进行传播：

表1事务传播行为类型

事务传播行为类型
 说明
 
PROPAGATION_REQUIRED
 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。
 
PROPAGATION_SUPPORTS
 支持当前事务，如果当前没有事务，就以非事务方式执行。
 
PROPAGATION_MANDATORY
 使用当前的事务，如果当前没有事务，就抛出异常。
 
PROPAGATION_REQUIRES_NEW
 新建事务，如果当前存在事务，把当前事务挂起。
 
PROPAGATION_NOT_SUPPORTED
 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
 
PROPAGATION_NEVER
 以非事务方式执行，如果当前存在事务，则抛出异常。
 
PROPAGATION_NESTED
 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。
 
一、事务的基本要素（ACID）

1、原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。

2、一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。
　　 3、隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账

4、持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。

二、事务的并发问题

　　1、脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据

　　2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。

　　3、幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。

　　小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表


三、MySQL事务隔离级别

事务隔离级别	            	脏读	不可重复读	幻读
读未提交（read-uncommitted）	是		是			是
不可重复读（read-committed）	否		是			是
可重复读（repeatable-read）		否		否			是
串行化（serializable）			否		否			否

mysql默认的事务隔离级别为repeatable-read
===================
static{}，这叫静初始化代码块。静态初始化代码块在类加载的时候执行，这是在任何对象创建之前，且只执行一次。
{}，这个是：代码块。在创建对象之前执行，
===========================================================================================================================================================================================================================================================================================================================
一、Docker是什么
Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。
Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心复杂环境问题。
总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。

二、Docker容器与传统虚拟机技术的特性对比


三、Docker的优势
更快速的交付和部署
Docker在整个开发周期都可以完美的辅助你实现快速交付。Docker允许开发者在装有应用和服务本地容器做开发。可以直接集成到可持续开发流程中。
例如：开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间。
高效的部署和扩容
Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。
Docker的兼容性和轻量特性可以很轻松的实现负载的动态管理。你可以快速扩容或方便的下线你的应用和服务，这种速度趋近实时。
更高的资源利用率
Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而Docker 只需要启动 10 个隔离的应用即可。
更简单的管理
使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。

四、Docker版本
Docker 是一个开源的商业产品，有两个版本：社区版（Community Edition，缩写为 CE）和企业版（Enterprise Edition，缩写为 EE）。
Docker Community Edition（CE）适合希望开始使用Docker并尝试使用基于容器的应用程序的个人开发人员和小型团队。
Docker Enterprise Edition（EE）专为企业开发和IT团队而设计，他们可以在生产中大规模构建，发布和运行业务关键型应用程序。


五、系统版本及内核要求
要求内核大于3.0的以下三个版本64位
Bionic 18.04 (LTS)
Xenial 16.04 (LTS)
Trusty 14.04 (LTS)

六、Docker安装
#卸载旧版本(如果安装过旧版本的话)
$ sudo apt-get remove docker docker-engine docker.io
#确保 apt-get 包更新到最新
$ sudo apt-get update
# 安装
$ sudo apt-get install\ apt-transport-https\ ca-certificates\ curl\ software-     properties-common
$ sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo add-apt-repository\ "deb [arch=amd64] 
https://download.docker.com/linux/ubuntu\ $(lsb_release -cs)\ stable”
$ sudo apt-get update
$ sudo apt-get install docker-ce


Image、Container、Repository

七、Image（镜像）文件
Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。
image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形成你的 image。
image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般应该尽量使用现有的 image 文件，而不是自己制作。即使要定制，也应该基于通用的 image 文件进行add，而不是从零开始制作。
#查找镜像
$ sudo docker search <NAME>
#拉取镜像默认为latest
$ sudo docker pull <images-name>
#列出本机所有的镜像文件
$ sudo docker images
#删除镜像文件
$ sudo docker rmi <image-id>
#commit镜像
$ sudo docker commit [option] CONTAINER [REPOSITORY[:TAG]]
-a：提交镜像作者
-c：使用Dockerfile指令创建镜像
-m：提交说明
-p：commit时暂停容器
#查看镜像元数据
$ sudo docker inspect <image-id>

八、Container（容器）
容器(container)由image文件生成的实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。
#列出本机正在运行的容器
$ sudo docker ps
#列出本机所有的容器，包括终止运行的容器
$ sudo docker ps -a
上面命令的输出结果之中，包括容器的 ID。很多地方都需要提供这个 ID

#启动容器
$ sudo docker start <container>
#终止容器
$ sudo docker stop <container>
#重启容器
$ sudo docker restart <container>
注意：终止运行的容器文件，依然会占据硬盘空间
#删除容器
$ sudo docker rm <container>
docker run命令会从 image 文件，生成一个正在运行的容器实例。（注意：docker container run命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的docker image pull命令并不是必需的步骤。）
#以我们现有的容器部署命令示例
$ sudo docker run --name $image_name --log-opt max-size=10m \
-p $container_port:$container_port \
--network $network \
-v /var/log/$image_name:/application/logs \
-e SPRING_REFERENCE=test \
-e SPRING_SERVICE=test \
-e SPRING_PROFILE=test \
-d harbor.emc.top/test-fota/$image_name:latest”
-i: 以交互模式运行容器，通常与 -t 同时使用；
-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；
#进入容器
$ sudo docker exec -it <container> /bin/bash
#查看容器元数据
$ sudo docker inspect <container>
docker inspect 参数及作用可以自己去了解一下，另外可以结合grep、awk查找出需要的元数据。
例如：查看所有运行容器的IP地址
$ sudo docker inspect -f '{{.Name}} - {{.NetworkSettings.IPAddress }}' $(docker ps -aq)

九、Dockerfile 文件
学会使用 image 文件以后，接下来的问题就是，如何可以生成 image 文件？如果你要推广自己的软件，势必要自己制作 image 文件。
这就需要用到 Dockerfile 文件。它是一个文本文件，用来配置 image。Docker 根据 该文件生成二进制的 image 文件。
下面通过一个实例，演示如何编写 Dockerfile 文件。
FROM  node:8.4
COPY  . /app
WORKDIR  /app
RUN  npm install --registry=https://registry.npm.taobao.org
EXPOSE  3000
上面一共五行，含义如下。
FROM node:8.4：该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。
COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。
WORKDIR /app：指定接下来的工作路径为/app。
RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。
EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。
#创建镜像
$ sudo docker build -t [imagename:tag] .
$ sudo docker build -t [imagename:tag] -f  [dockerfile-path]

十、Docker-Compose
1. docker-compose 是什么？
docker-compose 是一个用来把 docker 自动化的东西。有了 docker-compose 你可以把所有复杂的 docker 操作全都一条命令，自动化的完成。
2. 为什么要用 docker-compose，它解决了什么？
用通俗的语言来说，我们平时操作 docker 还是很原始的一系列动作，你手动使用 docker 的动作可以拆分成：
找到一个系统镜像 // docker search
拉取一个镜像  // docker pull
运行镜像 // docker run -d -it 你的镜像
略..
这是最小的动作， 如果你要映射硬盘，设置nat网络或者桥接网络，等等…你就要做更多的 docker 操作， 这显然是非常没有效率的。
但是我们写在 docker-compose.yml 里面就很好了。 你只需要写好后只运行一句：
docker-compose up -d
一切都是那么的简单。
3. 安装Compose
在安装compose之前，要确保已经安装了docker1.3或以上版本 
sudo curl -L 
https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose 
sudo chmod +x /usr/local/bin/docker-compose  
CLI 说明（docker-compose 命令）
build 创建或者再建服务 服务被创建后会标记为project_service(比如composetest_db)，如果改变了一个服务的Dockerfile或者构建目录的内容，可以使用docker-compose build来重建它
help 显示命令的帮助和使用信息
kill 通过发送SIGKILL的信号强制停止运行的容器，这个信号可以选择性的通过，比如： docker-compose kill -s SIGKINT
logs 显示服务的日志输出
port 为端口绑定输出公共信息
ps 显示容器
pull 拉取服务镜像
rm 删除停止的容器
run 在服务上运行一个一次性命令，比如： docker-compose run web python manage.py shell
scale 设置为一个服务启动的容器数量，数量是以这样的参数形式指定的：service=num，比如： docker-compose scale web=2 worker=3
start 启动已经存在的容器作为一个服务
stop 停止运行的容器而不删除它们，它们可以使用命令docker-compose start重新启动起来
up 为一个服务构建、创建、启动、附加到容器 
docker-compose.yml命令说明
Image 标明image的ID，这个image ID可以是本地也可以是远程的，如果本地不存在，Compose会尝试去pull下来
image: ubuntu  
image: orchardup/postgresql  
image: a4bc65fd  

build 该参数指定Dockerfile文件的路径，该目录也是发送到守护进程的构建环境，Compose将会以一个已存在的名称进行构建并标记，并随后使用这个image
build: /path/to/build/dir  

links 连接到其他服务中的容器，可以指定服务名称和这个链接的别名，或者只指定服务名称
links:  
 - db  
 - db:database  
 - redis 
此时，在容器内部，会在/etc/hosts文件中用别名创建一个条目，就像这样：
172.17.2.186  db  
172.17.2.186  database  
172.17.2.186  redis

ports 暴露端口，指定两者的端口（主机：容器），或者只是容器的端口（主机会被随机分配一个端口）ports:  
 - "3000"  
 - "8000:8000"  
 - "49100:22"  
 - "127.0.0.1:8001:8001"  

expose 暴露端口而不必向主机发布它们，而只是会向链接的服务（linked service）提供，只有内部端口可以被指定
expose:  
 - "3000"  
 - “8000"

volumes 挂载路径作为，可以选择性的指定一个主机上的路径（主机：容器），或是一种可使用的模式（主机：容器：ro）
volumes_from:  
 - service_name  
 - container_name  
 
environment 加入环境变量，可以使用数组或者字典，只有一个key的环境变量可以在运行Compose的机器上找到对应的值，这有助于加密的或者特殊主机的值
environment:  
  RACK_ENV: development  
  SESSION_SECRET:  
environments:  
  - RACK_ENV=development  
  - SESSION_SECRET  

env_file 从一个文件中加入环境变量，该文件可以是一个单独的值或者一张列表，在environment中指定的环境变量将会重写这些值
env_file:  
  - .env  
RACK_ENV: development  

net 网络模式，可以在docker客户端的--net参数中指定这些值
net: "bridge"  
net: "none"  
net: "container:[name or id]"  
net: "host" 

docker-compose.yml示例
version: '2'

networks:
    monitor:
        driver: bridge

services:
    prometheus:
        image: prom/prometheus
        container_name: prometheus
        hostname: prometheus
        restart: always
        volumes:
            - /Users/caizh/fsdownload/prometheus.yml:/etc/prometheus/prometheus.yml
            - /Users/caizh/fsdownload/node_down.yml:/etc/prometheus/node_down.yml
            - /Users/caizh/fsdownload/memory_over.yml:/etc/prometheus/memory_over.yml
            - /Users/caizh/fsdownload/record_rule.yml:/etc/prometheus/record_rule.yml
        ports:
            - "9090:9090"
        networks:
            - monitor

    alertmanager:
        image: prom/alertmanager
        container_name: alertmanager
        hostname: alertmanager
        restart: always
        volumes:
            - /Users/sf/fsdownload/config.yml:/etc/alertmanager/config.yml
        ports:
            - "9093:9093"
        networks:
            - monitor

    grafana:
        image: grafana/grafana
        container_name: grafana
        hostname: grafana
        restart: always
        ports:
            - "3000:3000"
        networks:
            - monitor

十一、doker和主机通信
这里先要来说一下docker网络的四种方式：
Host模式
Container模式
None模式
Bridge模式

1. Host模式
Host 模式并没有为容器创建一个隔离的网络环境。该模式下的Docker 容器会和Host宿主机共享同一个网络namespace， Docker Container。可以和宿主机一样，使用宿主机的eth0，实现和外界的通信。
Host模式特点包括：
容器没有隔离的 network namespace
容器的 IP 地址同 Docker host 的 IP 地址
注意：容器中服务端口号不能与Host宿主机上已经使用的端口号相冲突
host 模式能够和其它模式共存

2. Container模式
Container网络模式是 Docker 中一种较为特别的网络的模式。处于这个模式下的 Docker 容器会共享其他容器的网络环境，因此，至少这两个容器之间不存在网络隔离，而这两个容器又与宿主机以及除此之外其他的容器存在网络隔离。

3. None模式
None 网络就是什么都没有的网络。挂在这个网络下的容器除了 lo，没有其他任何网卡。需要我们自行去配置。

4. Bridge模式
Docker 容器默认使用Bridge模式的网络。Docker的Bridge模式和VM虚拟机的Bridge模式不同，虽然也叫Bridge，但实质上类似于VM的NAT模式。

原理是在宿主机上虚出一块网卡bridge0，然后所有容器会桥接在这块网卡的网段上。
默认情况下容器能访问外部网络，但外部网络无法访问容器，需要通过暴露容器端口的方式（docker run -p）让外部网络访问容器内的服务。
=================================================================================================================================================================
 
 CENTOS7.5安装docker；
 1、由于docker是必须在内核版本在3.1以上的linux系统上安装；

  uname -r   ：查看当前linux的的内核版本；

 2、yum install docker -y    ：在根目录执行安装docker命令；
 
 3、docker -v      ：查看docker的版本号；
 
 4、systemctl start docker    ：启动docker；
 
 5、systemctl stop docker     :停止docker；
 
 6、systemctl enable docker   :将docker安装设置为开机启动；
 
 7、docker search mysql       ：搜索MySQL镜像；
 
 8、docker pull mysql         ：从docker的公共仓库中拉取MySQL的默认镜像；
 
 9、docker images             ：查看当前docker中是否安装了哪些镜像；
 
 10、docker rmi (images ID)   ：删除镜像（镜像ID）；
 
 11、docker ps				  ：查看安装并启动的镜像；
 
 12、docker ps -a             ：查看所有的已启动的镜像实例；
 
 13、删除一个镜像实例时，必须停止要删除的镜像实例：  docker rm  (images id(镜像实例的ID))
 
 14、启动一个镜像实例：docker run --name 指定的实例名称
 
 15、启动一个完成端口映射的镜像实例：docker run -d(标识后台运行) -p(指定映射的端口号(主机端口号:容器内部端口号))  (mysql(必填指的是容器的REPOSITORY(docker images命令查出来的第一列))) 
 
 16、查看正在运行的镜像实例日志：docker logs mysql ;
     实时查看日志：docker logs -f mysql(容器运行的ID)
	 
 17、docker上启动MySQL镜像实例：docker run --name MySQL3306 -e MYSQL_ROOT_PASSWORD=1234567 -d mysql
 
 18、docker上启动带映射的MySQL镜像实例：docker run -p 3307:3306 --name MySQL3306 -e MYSQL_ROOT_PASSWORD=1234567 -d mysql
 
 19、docker上启动带映射并设置字符集的MySQL镜像实例：
	 docker run -p 3308:3306 --name mysql3308 -e MYSQL_ROOT_PASSWORD=1234567 -d mysql --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
		#进入MySQL镜像实例容器中
		docker exec -it MySQL3306(镜像名称) bash
		docker exec -it 55b1faff3521 bash
		#退出容器：
		exit;
		#登录mysql
		mysql -u root -p
		ALTER USER 'root'@'localhost' IDENTIFIED BY '1234567';
		客户端在使用root连接的时候会出现：client does not support authentication protocol requested by server;consider upgrading mysql client 
		#添加远程登录用户
		CREATE USER 'qjyn1314'@'%' IDENTIFIED WITH mysql_native_password BY '1234567';
		GRANT ALL PRIVILEGES ON *.* TO 'qjyn1314'@'%';
		#程序中的应用是：
		 IP地址是公网的IP地址
		#账号分别是
		 root:1234567
		 qjyn1314:1234567
		#程序在链接数据库(docker默认安装的是mysql最新版本)时出现的问题：
		 1、Could not retrieve transation read-only status server
			解决：
			 将pom文件中的MySQL链接的的驱动换成Maven仓库中最新版本，
				<dependency>
					<groupId>mysql</groupId>
					<artifactId>mysql-connector-java</artifactId>
					<version>8.0.13</version>
				</dependency>
		 2、在MySQL5.7之后默认不开启，group by的函数的问题：
		    SELECT @@GLOBAL.sql_mode;
            SELECT @@SESSION.sql_mode;
			set sql_mode ='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';
			

 20、docker安装jenkins
		#搜索jenkins
		docker search jenkins
		#拉取jenkins镜像
		docker pull jenkins
		#创建主机的jenkins文件存储路径
		mkdir /usr/local/jenkins
		#运行带映射端口的jenkins，并指定文件配置路径
		docker run -p 8080:8080 -p 50000:50000 -v /usr/local/jenkins:/var/jenkins_home -d jenkins
		docker run -d --name myjenkins -p 8080:8080 -p 50000:50000 -v /usr/local/jenkins/data:/var/jenkins_home jenkins
		#查看是否启动成功
		docker ps -a 
		#查看日志
		docker logs jenkins的启动后的容器ID
		#得到密码
		Please use the following password to proceed to installation:
		d406a25e9e2c49b4ad42a9205cedba80    #此字符串为jenkins的admin密码；
		This may also be found at: /var/jenkins_home/secrets/initialAdminPassword
		然后紧接着进行操作。
		
 21、docker安装redis
		#搜索redis
		docker search redis
		#拉取redis
		docker pull redis
		#运行带参数的redis，并指定密码
		docker run --name redis6666 -p 6666:6379 -d redis --requirepass "1234567"
		#查看运行成功的redis
		docker ps -a
		程序中应用的：ip地址是，服务器的公网ip，端口号是6666。
	
 22、docker安装zookeeper
		#搜索zookeeper
		docker search zookeeper
		#拉取zookeeper
		docker pull zookeeper
		#运行带参数的zookeeper
		docker run --name zookeeper4181 --restart always -p 4181:2181 -d zookeeper
		docker run --name zookeeper4182 --restart always -p 4182:2181 -d zookeeper
		docker run --name zookeeper4183 --restart always -p 4183:2181 -d zookeeper
		程序中的使用:dubbo配置文件中的ip地址以及端口号是：47.104.78.115:4181
		
 23、docker安装rabbit
		#搜索rabbit
		docker search rabbit
		#拉取rabbit
		docker pull rabbit 
		#运行带参数的rabbit
		docker run -d --hostname my-rabbit5672 --name rabbit5672 -p 5672:5672 rabbitmq
		#查看实时日志：docker logs -f 正在运行的容器ID
		47.104.78.115:5672
	
	docker安装带管理页面的rabbitmq(rabbitmq:management)
	#搜索rabbitmq:management
	docker search rabbitmq:management
	#拉取rabbitmq:management
	docker pull rabbitmq:management
	#运行带管理界面的rabbitmq:management
	docker run -d --name rabbitmqAndManager --publish 5671:5671 --publish 5672:5672 --publish 4369:4369 --publish 5674:25672 --publish 5675:15671 --publish 5676:15672 rabbitmq:management
	#访问管理页面：
	47.104.78.115:5676   即可打开rabbitmq的管理页面
	默认的登录账户密码：guest：guest
	1、创建一个admin权限的admin,admin123的一个用户，需要在程序中使用这个用户的账号和密码
	2、或者直接使用默认的账户密码也行
 
 24、docker安装mongodb
	#搜索MongoDB
	docker search mongo
	#拉取mongo
	docker pull mongo
	#运行带参数的mongo
	docker run -p 27017:27017 -v /usr/local/mongo/data:/data/db --name mongodb27017 -d mongo
	#查看实时日志：
	docker logs -f 正在运行的容器ID
	#进入 mongo 交互模式
	docker exec -it <CONTAINER NAME> mongo admin
	docker exec -it mongodb27017 mongo admin
====================================================================================================================================================


张孝祥
javaWeb马士兵

java类加载：
1、java虚拟机使用每一个类的第一件事请就是将该类的字节码装载进来，装载类字节码的功能是由类装载器完成的，类装载器负责根据一个类的名称来定位和生成类的字节码数据后返回给java虚拟机
2、类加载器本身也是一个java类，java虚拟机也允许开发人员编写自己的类装载器，以便通过其他各种特殊方式来产生类字节码。
3、不管类装载器采用什么方式，只要能够在内存中制造出给java虚拟机调用类字节码即可，所以，把类装载器描述为类字节码的制造器更容易让人理解。
4、当一个类被加载后，java虚拟机将其编译为可执行代码存储在内存中，并将索引信息存储进一个hashtable中，其索引关键字为与之相对应的类名。
java虚拟机中，首先会在hashtable中查找java类字节码，若是找不到，则进行编译

5、java程序中的类本身也是一种事物，他也可以用一个java类来描述，这个特殊的类名就叫class。类装载器装载某各类的字节码的过程就是在创建class类的实例翠香，这个class类的实例对象封装的内容正好是当前加载的类的字节码数据。

获取某各类的字节码数据的class实例对象，可以使用下面三种方式，
1.类名.class  2.对象.getClass() 3.Class.forName("类名")  

java类库中提供了一个java.lang.ClassLoader 类作为类装载器的基类，java虚拟机和程序都调用classLoader类的loadClass方法来加载类，
ClassLoader是一个抽象类，真正的类装载器必须是classLocader的子类，
Class类中定义了一个getClassLoader方法，用于返回他所描述的类的而来加载器对象，这个返回对象的类型是classLoader。


类装载器的基本策略：
一个类装载器本身也是一个java类，所以类装载器也需要被另外一个类装载器装载

java虚拟机中内嵌了一个称为bootstrap的类装载器（是特定于操作系统的本地代码实现的，属于java虚拟机的内核，不用类装载器装载），
bootstrap类装载器负责加载java核心包中的类，这些类的class.getClassLoader犯法返回值为null，表示是bootstrap类装载器。

在java核心包中，
ExtClassLoader类装载器负责加载存放在JAVA_HOME/jre/lib/ext目录下的jar包中的类
AppClassLoader负责加载应用程序启动执行类


一个java虚拟机中的所有类装载器采用具有父子关系的属性结构进行组织，在实例化梅格雷装载器对象时，需要为其执行一个父级类装载器对象，如果没有执行的话，则以ClassLoader.getSystemClassLoader()方法返回的系统类装载器作为其父级类装载器对象


系统类装载器通常被设置为启动应用程序的AppClassLoader，可以通过java.system.class.loader系统属性来将系统类装载器设置为其他类装载器，WxtClassLoader是AppClassLoader父级类装载器，ExtClassLoader没有父级类装载器。

每个ClassLoader本身只能分别加载特定位置和目录中的类，但是ClassLoader被设计成了一个委托模式，是的某一个ClassLoader可以委托他的父级装载器去加载类，从而让应用程序可以借助某一个自己的ClassLoader去多个位置和目录中进行类的加载。

***************************************
当要加载一个类时，ClassLoader的LoadeClass方法先查找这个类的是否已被加载，
如果没有加载则委托其父级类装载器去加载这个类，
	如果父级的类装载器无法装载这个类，
		则子级类装载器才调用自己内部的findClass方法去进行真正的加载。
		其委托过程会一直追溯到Bootstrap类装载器，
	如果委托过程中的所有类装载器，都不能完成类的装载，
	最终就会报告ClassNotFoundException异常。
****************************************

一个类装载器只能创建某个类的一份字节码数据，即只能为某个类创建一个与之对应的Class实例对象。

在一个java虚拟机中可以存在多个类加载器，每个类加载器都拥有自己的名称空间，对于同一个类，每个类加载器都可以创建出它的一个Class实例对象。

****************************************
采用委托模式的原因：
避免了一个java虚拟机中的多个类加载器为同一个类创建多份字节码数据的情况，
只要开发人员自定义的类装载器不覆盖ClassLoader的LoaderClass方法，而是覆盖其findClass方法，这样就可以继续采用委托模式。
当loadClass没有加载成功的时候，就会使用findClass方法，进行具体的加载
****************************************

每个类装载器是不能实现数据共享的。

线程中的类加载器：

如果在类A中使用new 关键字创建类B，java虚拟机将使用加载类A的类装载器来加载类B。
如果在一个类中调用Class.forName方法的一个参数来指定类B的类装载器。
如果没有指定该参数，则使用加载房钱类的类装载器。

每个运行中的线程都有一个关联的上下文类加载器，可以使用
Thread.setContextClassLoader()方法设置线程的上下文类装载器。

每个线程默认的上下文类装载器是其负线程的上下文类装载器，而主线程的类装载器初始被设置为ClassLoader.getSystemClassLoader()方法返回的系统类加载器。

当前线程中运行的代码需要使用某个类时，它使用上下文类装载器来装载这个类，上下文类装载器首先会委托他的父级类装载器来装载这个类， 如果父级类装载器无法装载时，上下文类装载器才自己进行装载。

TOMCAT中的类装载器：

Syatem即系统类装载器，通常情况下就是AppClassLoader，负责加载CLASSPATH环境变量，只包含tool.jar、bootatarp.jar 的两个包。

common类装载器负责从CLASS_HOME/common/classes中的.class文件
和CLASS_HOME/common/lib中的jar包加载类。

catalina类装载器(tomcat内核)负责从CLASS_HOME/service/classes中的.class文件

shared类装载器负责从CLASS_HOME/




























==============================================================================================================================================================================================================================

echo "启动脚本"
cd /usr/local/git/gitproject/jack/
echo "进入【/usr/local/git/gitproject/jack/】目录拉取最新的代码"
git pull

echo "进行项目编译【mvn clean install -U】"
mvn clean install -U

echo "进入【target】目录"
cd web-jack/target/

echo "将原有的【web-jack】项目删除"
rm -rf /home/project/web-jack-0.0.1-SNAPSHOT.jar

echo "将刚刚编译通过的【web-jack】项目拷贝到【/home/project/】"
cp web-jack-0.0.1-SNAPSHOT.jar /home/project/

echo "将原来的项目停止"
echo "查看之前启动的项目进程和端口号"
netstat -ntulp |grep java

echo "将之前的项目进程号杀掉"


echo "启动项目并将其启动为后台运行项目"
nohup java -jar web-jack-0.0.1-SNAPSHOT.jar >/home/project/logs/catalina.out 2>&1 &

echo "查看启动日志"
tail -f /home/project/logs/catalina.out

==============================================================================================================================================
 Springboot(1.5.19)的启动原理以及启动步骤(大部分版本的启动方式)：
	1、创建SpringApplication对象，
		1.initialize();方法，
		if (sources != null && sources.length > 0) {
		//保存主配置类
            this.sources.addAll(Arrays.asList(sources));
        }
		//判断当前应用是否是web应用
        this.webEnvironment = this.deduceWebEnvironment();
        //加载MATE/INFO下面的springboot.factories配置的所有ApplicationContextInitializers,(找到自动配置类)并保存。
		this.setInitializers(this.getSpringFactoriesInstances(ApplicationContextInitializer.class));
	    //加载MATE/INFO下面的springboot.factories配置的所有ApplicationListener,(找到监听器)并保存。
        this.setListeners(this.getSpringFactoriesInstances(ApplicationListener.class));
		//从多个配置类中找到带有main方法的主配置类
        this.mainApplicationClass = this.deduceMainApplicationClass();
		
	
	2、运行run方法，
	 public ConfigurableApplicationContext run(String... args) {
        StopWatch stopWatch = new StopWatch();
        stopWatch.start();
        ConfigurableApplicationContext context = null;
        FailureAnalyzers analyzers = null;
        this.configureHeadlessProperty();
		//获取SpringApplicationRunListeners：从类路径下META-INF下获取监听器，
        SpringApplicationRunListeners listeners = this.getRunListeners(args);
        //回调所有的获取SpringApplicationRunListeners的starting()方法，
		listeners.starting();
        try {
			//开启
            ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
            //准备环境并创建：IOC环境，
			ConfigurableEnvironment environment = this.prepareEnvironment(listeners, applicationArguments);
			//创建完成SpringApplicationRunListeners，ApplicationArguments，并打印banner；
            Banner printedBanner = this.printBanner(environment);
			//创建ApplicationContext，根据是否是web应用，利用反射，来创建IOC容器；
            context = this.createApplicationContext();
            new FailureAnalyzers(context);
			//准备上下文环境：将environment保存在ioc中；其中applyInitializers方法里面调用ApplicationContextInitializer的initialize()方法，
			//将初始化器进行回调，将环境都准备好之后，回调的方法：SpringApplicationRunListeners的contextLoaded(),在方法的最后执行；
			this.prepareContext(context, environment, listeners, applicationArguments, printedBanner);
			//刷新容器，初始化ioc容器，同步的并创建安全的容器(如果是web应用还会创建嵌入式的tomcat)，
			//扫描，创建，加载所有组件的地方；(配置类，组件，自动配置)
            this.refreshContext(context);
			//从ioc容器中获取ApplicationRunner和CommandLineRunner，；来进行回调
            this.afterRefresh(context, applicationArguments);
			//所有的SpringApplicationRunListener回调finished，进行启动；
            listeners.finished(context, (Throwable)null);
            stopWatch.stop();
            if (this.logStartupInfo) {
                (new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), stopWatch);
            }
            return context;
        } catch (Throwable var9) {
            this.handleRunFailure(context, listeners, (FailureAnalyzers)analyzers, var9);
            throw new IllegalStateException(var9);
        }
    }
		
		
================
================
==========================	
	CENTOS7安装hadoop

1、hostname 
   查看当前linux上的hostname是什么
   hostname Master   -->将hostname 修改为：Master
 
2、修改hosts文件
	vim /etc/hosts 
	新增 47.104.78.115  Master 
	
	检测是否修改成功：
	使用  ping Master 将出现一下效果：
	[root@izm5e9ibpdra8rjti7v0xrz hadoop]# ping Master
	PING Master (47.104.78.115) 56(84) bytes of data.
	64 bytes from Master (47.104.78.115): icmp_seq=1 ttl=64 time=0.221 ms
	64 bytes from Master (47.104.78.115): icmp_seq=2 ttl=64 time=0.214 ms
	64 bytes from Master (47.104.78.115): icmp_seq=3 ttl=64 time=0.201 ms
 3、

=====================================================================================================================================
https://git.io/vpnsetup-centos
wget https://git.io/vpnsetup -O vpnsetup.sh && sudo sh vpnsetup.sh

wget https://git.io/vpnsetup-centos -O vpnsetup.sh && sudo sh vpnsetup.sh

==============================================================================================================================================================
 

linux安装zookeeper
：

clean是告诉maven清理输出目录target
compile是告诉maven编译项目主代码，
从输出中看到maven
首先执行了clean任务，删除target目录
默认情况下maven构建的所有输出都在target目录中，
接着执行resources任务
最后执行了compile




















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































